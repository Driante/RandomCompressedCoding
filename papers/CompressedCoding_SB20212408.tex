%% Language and font encodings
%% Sets page size and margins
%% Useful packages
% Recommended
% Trang-Anh's comments
%Rava's comment
% Mirko's comments

\documentclass[a4paper]{article}%
\usepackage{eurosym}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{subcaption}
\usepackage{caption}
\usepackage{graphicx}
\usepackage[a4paper,top=3cm,bottom=2cm,left=2cm,right=2cm,marginparwidth=1.75cm]%
{geometry}
\usepackage{amsfonts}
\usepackage{natbib}
\usepackage{csquotes}
\usepackage[tbtags]{amsmath}
\usepackage{svg}
\usepackage{bm}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage[english]{fancyref}
\usepackage{authblk}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}%
\setcounter{MaxMatrixCols}{30}
%TCIDATA{OutputFilter=latex2.dll}
%TCIDATA{Version=5.50.0.2960}
%TCIDATA{LastRevised=Sunday, July 18, 2021 16:55:33}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{<META NAME="SaveForMode" CONTENT="1">}
%TCIDATA{BibliographyScheme=BibTeX}
%TCIDATA{Language=American English}
%BeginMSIPreambleData
\providecommand{\U}[1]{\protect\rule{.1in}{.1in}}
%EndMSIPreambleData
\DeclareCaptionLabelFormat{adja-page}{\hrulefill\\#1 #2 \emph{(previous page)}}
\bibliographystyle{neuron}
\def\TA#1{\textcolor{blue}{#1}}
\def\RA#1{\textcolor{red}{#1}}
\definecolor{Mirko}{HTML}{117A65}
\def\MP#1{\textcolor{Mirko}{#1}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator\erf{erf}
\DeclareMathOperator\erfc{erfc}
\title{Random Compressed Coding with Neurons}
\author[1]{Simone Blanco Malerba}
\author[1]{Mirko Pieropan\thanks{Current affiliation: Department of Applied Science and Technology (DISAT), Politecnico di Torino,
Corso Duca degli Abruzzi 24, Torino}}
\author[2,3]{Yoram Burak}
\author[1,4,5]{Rava da Silveira}

\affil[1]{Laboratoire de Physique de l'Ecole Normale Sup\'erieure, ENS, Universit\'e PSL, CNRS, Sorbonne Universit\'e, Universit\'e de Paris, Paris}
\affil[2]{Racah Institute of Physics, Hebrew University of Jerusalem, Jerusalem}
\affil[3]{Edmond and Lily Safra Center for Brain Sciences, Hebrew University of Jerusalem, Jerusalem}
\affil[4]{Institute of Molecular and Clinical Ophthalmology Basel, Basel}
\affil[5]{Faculty of Science, University of Basel, Basel}
\begin{document}
\title{Random Compressed Coding with Neurons}
\maketitle
\begin{abstract}
The brain encodes information about the sensory world in the activity of
neural populations. In classical population coding models, the responses of
single neurons are described by simple, unimodal or monotonic, smooth `tuning
curves'. But various more complex tuning curves have been observed. In the
case of grid cells, for example, response periodicity imparts the population
code with high accuracy. Here, we ask whether highly accurate codes require a
fine response design, as in the case of grid cells, or obtain more generally.
To address this question, we consider a simple, shallow network that produces
complex but unstructured tuning curves, and we examine `efficient population
coding' in the output layer. Specifically, we optimize the properties of
response functions in the input, `sensory' layer in terms of the information
represented in the output layer. Irregularity of the responses in the output
layer gives rise to the possibility of catastrophic coding errors. Our
optimization approach, unlike most efficient coding procedures which consider
peripheral neurons only, yields a non-trivial solution in which the width of
sensory tuning curves ensures a balance between `global' (or catastrophic)
errors and `local' errors. In this regime, information is efficiently
compressed from a large sensory layer to a small `representation' layer, and
accuracy is exponential in population size. We revisit data from monkey motor
cortex in the light of our approach, where we suggest that a similar
compression of information takes place. Efficient (neural) codes do not
require a fine design of response properties, but can occur in the presence of
randomness, as indeed pointed out by Shannon seventy years ago.

\end{abstract}

\bigskip

\section{Introduction}

Neurons convey information about the physical world by modulating their
responses as a function of parameters of sensory stimuli. Classically, the
mean neural response to a stimulus --- referred to as the neuron's `tuning
curve' --- is often described as a smooth function of a stimulus parameter
with a simple monotonic or unimodal form
\cite[]{Hubel1959ReceptiveCortex,Georgopoulos1982OnCortex,Taube1990Head-directionAnalysis,Miller1991RepresentationInterneurons,Bremmer1997EyeMST,Dayan2001TheoreticalSystems,Kayaert2005TuningCortex}. The deviation from the mean response --- the `neural noise' --- may lead to
ambiguity in the identity or strength of the encoded stimulus, and the coding
performance of a population of neurons as a whole is dictated by the forms of
the tuning curves and the joint neural noise. In the study of population
codes, the efficient coding hypothesis has served as a theoretical organizing
principle. It posits that tuning curves are arranged in such a way as to
achieve the most accurate coding possible given a constraint on the neural
resources engaged
\cite[]{Barlow1961PossibleMessages,Atick1990TowardsProcessing,Lewicki2002EfficientSounds}. The latter is often interpreted as a metabolic constraint on the maximum
firing rate of a single neuron or on the mean firing rate of the whole
population
\cite[]{Zhang1999NeuronalBroaden,Bethge2002OptimalFails,Wang2016EfficientError}.

In order to tackle this constrained optimization problem in practice, tuning
curves are parametrized, and the corresponding parameters are optimized. Here,
the simplicity of the form of tuning curves matters:\ only a few parameters
need to be optimized. A large body of literature addresses this constrained
optimization problem, in particular in the perceptual domain. For example,
many studies model tuning curves as Gaussian or other bell-shaped functions,
and obtain the values of their \textbf{[SIMONE to RAVA: 'means and variances'. Since we are talking about functions and not distributions, I would use centers and widths, also to be coherent with the terms used later.]} centers and widths that minimize the
`perceptual' error committed when information is decoded from the activity of
a population of model neurons
\cite[]{Zhang1999NeuronalBroaden,Deneve1999ReadingObservers,Yaeli2010Error-basedNeurons,Ganguli2014EfficientPopulations,Fiscella2015VisualNeurons}. In the resulting optimal populations, and if noise among neurons is
independent, the coding error typically scales like $1/\sqrt{N}$, where $N$ is
the number of model neurons \cite[]{Seung1993SimpleCodes}. This behavior can be
intuited based on the observation that the `signal' in the neural population
grows like $N$ while the noise grows like $\sqrt{N}$, yielding a
signal-to-noise ratio that increases in proportion to the square root of the
population size. (In some models of population neural coding of a
one-dimensional parameter, the width of tuning curves can be further optimized
to yield an additional factor of $1/\sqrt{N}$; the error then scales like
$1/N$ \cite[]{Berens2011ReassessingFunctions,Kim2020SuperlinearCodes}.)

Real neurons, however, can come with much more complex tuning curves than
simple Gaussian or bell-shaped ones. Grid cells recorded in the enthorinal
cortex offer a salient example
\cite[]{Hafting2005MicrostructureCortex,Doeller2010EvidenceNetwork,Yartsev2011GridBats,Killian2012ACortex}
; their tuning curves are multimodal and periodic as a function of spatial
coordinates. A number of other examples of neurons with complex tuning curves
have also been identified in other cortical regions, in different species
\cite[]{Kadia2003SpectralCharacteristics,Sofroniew2015NeuralLocomotion,Lalazar2016TuningConnectivity,Gaucher2020ComplexitySpecies,Eliav2021MultiscaleBats}. It was noted early on that such richer tuning curves can give rise to
greatly enhanced codes. Given the periodicity of their tuning curves, and
provided that the neural population include several modules made up of cells
with different periodicities \cite[]{Fiete2008WhatLocation,Wei2015ACells}, grid
cells can represent spatial location with an accuracy that scales
exponentially (rather than algebraically, as above) in the number of neurons
\cite[]{Sreenivasan2011GridComputation,Mathis2012ResolutionNeurons,Burak2014SpatialCortex}. Thus, the richer structure of individual tuning curves can be traded for a
strong boost in the efficiency of the population code.

Here, we ask whether highly efficient codes of this sort must rely on
finely-tuned properties, such as the tuning curves' periodicity or the
arrangement of different modules in the population, or, alternatively, arise
generically and robustly in populations of neurons with complex tuning curves,
in the absence of any fine-tuning. We approach the question by studying the
benchmark case of a random neural code: a population code that relies on
irregular tuning curves that emerge from a simple, feedforward, shallow
network with random synaptic weights. The input layer in the network is made
up of a large array of `sensory' neurons with classical, bell-shaped tuning
curves; these neurons project to a small array of `representation' neurons
with complex tuning curves. We show that, in the resulting population code,
the coding error is suppressed exponentially with the number of neurons in the
population, even in the presence of high-amplitude noise.

In the context of this highly efficient code, it is not sufficient to consider
a `typical error': efficiency results from the compression of the stimulus
space into the activity of a layer of neurons of comparatively small size; the
price to pay for this compression is the emergence of two qualitatively
distinct types of error---`local errors', in which the encoding of nearby
stimuli is ambiguous, and `global (or catastrophic) errors', in which the
identity of the true stimulus is lost altogether. The efficient coding problem
then translates into a trade-off between these two types of errors. In turn,
this trade-off yields an optimal width of the tuning curves in the `sensory
layer': when stimulus information is compressed into a `representation layer',
tuning curves in the sensory layers have to be sufficiently wide as to prevent
a prohibitive rate of global errors.

We first develop the theory for a one-dimensional input (e.g., a spatial
location along a line or an angle), then generalize it to higher-dimensional
inputs. The latter case is more subtle because the sensory layer itself can be
arranged in a number of ways (while still operating with simple, classical
tuning curves). This generalization allows us to apply our model to data from
monkey motor cortex, where cells display complex tuning curves. We fit our
model to the data and discuss the merit of a complex `representation code'.
Overall, our approach can be viewed as an application of the efficient coding
principle to downstream (`representation') processing, as opposed to the more
common applications to peripheral (sensory) processing. Our study extends
earlier theoretical work on grid cells and other `finely designed' codes by
proposing that efficient compression of information can occur robustly even in
the case of a random network. We reach our results by considering the geometry
of population activity in a compressed, representation layer of neurons.

\section{Results}

We organize the description of our results as follows. First, we present, in
geometric terms, the qualitative difference between a code that uses simple,
bell-shaped tuning curves and one that uses more complex forms. Second, we
introduce a simple model of a shallow, feedforward network of neurons that can
interpolate between simple and complex tuning curves depending on the values
of its parameters. Third, we characterize the accuracy of the neural code in
the limiting case of maximally irregular tuning curves. Fourth, we extend the
discussion to the more general case in which an optimal code is obtained from
a trade-off between local and global errors. All the above is done for the
case of a one-dimensional input space. Fifth, we generalize our approach to
the case of a multi-dimensional stimulus. This allows us, sixth, to apply our
model to recordings of motor neurons in monkey, and to analyze the nature of
population coding in that system. \textbf{[SIMONE: Added geometry paragraph.]}Seventh, we give a quantitative description of the geometry of the population response induced by our network as a function of its parameters, in particular through a measure of `dimensionality'. Finally, we extend our model to include an
additional source of noise---`input noise' in the sensory layer, in addition
to the `output noise' present in the representation layer; input noise gives
rise to correlated noise downstream, and we analyze its impact on the
population code.

\subsection*{The geometry of neural coding with simple vs. complex tuning
curves}

A neural code is a mapping that associates given stimuli to a probability
distribution of spiking patterns; in particular, the code maps any given
stimulus to a mean population activity. In the case of a continuous,
one-dimensional stimulus space, the latter is mapped into a curve in the
$N$-dimensional space of the population activity, whose shape is dictated by
the form of the tuning curves of individual neurons. As an illustration, we
compare the cases of three neurons with bell-shaped (here, Gaussian) tuning
curves and three neurons with periodic (grid-cell-like) tuning curves with
three different periods (Fig. \ref{Fig:1}A). Simple tuning curves generate a
smooth population response curve, implying that similar stimuli are mapped to
nearby responses; by contrast, more complex tuning curves give rise to a
serpentine curve. The latter makes better use of the space of possible
population responses than the former, and hence can be expected to yield
higher-resolution coding. Indeed, when the population response is corrupted by
noise of a given magnitude, it will elicit a smaller \textit{local} error in
the case of complex tuning than in the case of simple tuning: by `stretching'
the mean response curve over a longer trajectory within the space of possible
population activities, complex tuning affords the code with higher resolution
relative to the range of the encoded variable. However, this argument does not
capture in full the influence of noise on the nature of coding errors. In the
case of a winding and twisting mean response curve, two distant stimuli are
sometimes mapped to nearby activity patterns. In the presence of noise, this
geometry gives rise to \textit{global} (or catastrophic) errors. The enhanced
resolution of the neural code associated with the occurrence of global errors
was also noted in the context of grid-cell coding
\cite[]{Welinder2008GridLearning,Sreenivasan2011GridComputation}. Because of
this trade-off, whether a simple or complex coding scheme is preferable
becomes a quantitative question, which depends upon the details of the
structure of the encoding.

\subsection*{Shallow feedforward neural network as a benchmark for efficient
coding}

In order to address the problem mathematically, we examine the simplest
possible model that generates complex tuning curves, namely a two-layer
feedforward model. An important aspect of the model is that it does not rely
on any finely-tuned architecture or parameter tuning: complex tuning curves
emerge solely because of the variability in synaptic weights; thus, the model
can be thought of as a benchmark for the analysis of population coding in the
presence of complex tuning curves. The architecture of the model network and
the symbols associated with its various parts are illustrated in Fig.
\ref{Fig:1}B. In the first layer, a large population of $L$ \textit{sensory}
neurons encodes a one-dimensional stimulus, $x$, into a high-dimensional
representation. Throughout, we assume that $x$ takes values between zero and
one, without loss of generality. (If the input covered an arbitrary range, say
$r$, then the coding error would be expressed in proportion to $r$. In other
words, one cannot talk independently of the range of the input and of the
resolution of the code. We set the range to unity in order to avoid any
ambiguity.) Sensory neurons come with classical tuning curves: the mean firing
rate of neuron $j$ in response to stimulus $x$ is given by a Gaussian with
center $c_{j}$ (the preferred stimulus of that neurons) and width $\sigma$:
\begin{equation}
u_{j}\left(  x\right)  =A\exp\left(  -\frac{\left(  x-c_{j}\right)  ^{2}%
}{2\sigma^{2}}\right)  . \label{Eq:tuning-curve-layer1}%
\end{equation}
Following a long line of models, we assume that the preferred stimuli in the
population are evenly spaced, so that $c_{j}=j/L$. As a result, the response
vector for a stimulus $x_{0}$, $\mathbf{u}\left(  x_{0}\right)  $, can be
represented as a Gaussian `bump' of activity centered at $x_{0}$.

Complex tuning curves appear in the second layer containing $N$
\textit{representation} neurons; we shall be interested in instances with
$N\ll L$, in which efficient coding results in compression of the stimulus
information from a high-dimensional to a low-dimensional representation. Each
representation neuron receives random synapses from each of the sensory
neurons; specifically, the elements of the all-to-all synaptic matrix,
$\mathbf{W}$, are i.i.d. Gaussian random weights with vanishing mean and
variance equal to $1/L$ ($W_{ij}\sim\mathcal{N}\left(  0,1/L\right)  $). In
the simple, linear case that we consider, the mean response of neuron $i$ in
the second layer is thus given by
\begin{equation}
v_{i}\left(  x\right)  =\sum_{j=1}^{L}W_{ij}u_{j}\left(  x\right)  .
\label{Eq:tuning-curve-layer2}%
\end{equation}
Since the weights $W_{ij}$ correspond to a given realization of a random
process, they generate tuning curves, $v_{i}\left(  x\right)  $, with
irregular profiles. The parameter $\sigma$ is important in that it controls
the smoothness of the tuning curves in the second layer: it defines the width
of $u_{j}$, which in turn dictates the correlation between the values of the
tuning curve $v_{i}$ for two different stimuli. By the same token, the
amplitude of the variations of $v_{i}$ with $x$ depends upon the value of
$\sigma$. For a legitimate comparison of population codes in different
networks, we set this amplitude to a constant on average,
\begin{equation}
\left\langle \int_{0}^{1}dx\left[  v_{i}\left(  x\right)  -\int_{0}%
^{1}dx^{\prime}v_{i}\left(  x^{\prime}\right)  \right]  ^{2}\right\rangle
_{W}=R, \label{Eq:resource-limitation}%
\end{equation}
by calibrating the value of the prefactor in Eq. (\ref{Eq:tuning-curve-layer1}
), $A$. Because of the averaging over the synaptic weights, indicated by the
brackets $\langle\cdot\rangle_{W}$, $A$ does not depend upon a specific
realization of the synaptic weights. Equation (\ref{Eq:resource-limitation})
corresponds to the usual constraint of `resource limitation' in efficient
coding models; it amounts to setting a maximum to the variance of the output
over the stimulus space, as is commonly assumed in analyses of efficient
coding in sensory systems
\cite[]{Atick1990TowardsProcessing,VanHateren1998IndependentCortex,Doi2012EfficientRetina,Zhaoping2014UnderstandingData}.

Returning to our geometric picture, we observe that, by changing the value of
$\sigma$, we can interpolate between smooth and irregular tuning curves in the
second layer (Fig. \ref{Fig:1}C). In the limiting case of large $\sigma$,
representation neurons come with smooth tuning curves akin to classical ones;
in the other limiting case of small $\sigma$, the mean population response
curve becomes infinitely tangled. Thus, as the value of $\sigma$ is decreased,
the mean response curve `stretches out' and necessarily twists and turns, in
such a way as to fit within the allowed space of population responses defined
by Eq. (\ref{Eq:resource-limitation}). A longer population response curve
fills the space of population responses more efficiently and represents the
stimulus at a higher resolution, but its twists and turns may result in
greater susceptibility to noise.

To complete the definition of the model, we specify the nature of the noise in
the neural response. We assume that neuron $i$ in the second layer is affected
by i.i.d. noise, which we denote by $z_{i}$, such that its response at each
trial (in which stimulus $x$ is presented) is given by $r_{i}=v_{i}\left(
x\right)  +z_{i}$. For the sake of simplicity, we use Gaussian noise with
vanishing mean and variance equal to $\eta^{2}$. In most of our analyses, we
suppose that responses in the first layer are noiseless and that the noise in
the second layer is uncorrelated among neurons; in the last subsection,
however, we relax these assumptions, and discuss the implications of noisy
sensory neurons and correlated noise among representation neurons. (Our
motivation for considering noiseless sensory neurons is that we are primarily
interested in analyzing the compression of the representation of information
between the first and the second layer of neurons. By contrast, noise in
sensory neurons affects the fidelity of encoding in the \textit{first} layer.)
We quantify the performance of the code in the second layer through the mean
squared error (MSE) in the stimulus estimate as obtained from an ideal
decoder. The use of an ideal decoder is an abstract device that allows us to
focus on the uncertainty inherent to \textit{encoding} (rather than to
imperfections in \textit{decoding}); it is nevertheless possible to obtain a
close approximation to an ideal decoder in a simple neural network with
biologically plausible operations (see Methods).

\subsection*{Compressed coding in the limiting case of narrow sensory tuning}

It is instructive to study the properties of coding in our model in the
limiting case of neurons with narrow tuning curves in the sensory layer
($\sigma\rightarrow0$), because this limit yields the most irregular tuning
curves in the representation layer of our network (Fig. \ref{Fig:1}C). As we
shall see, this limiting case also corresponds to that of a completely
uncorrelated, random code, for which the mathematical analysis simplifies.
When the value of $\sigma$ is much smaller than $1/L$, neurons in the sensory
layers respond only if the stimulus coincides with the preferred stimulus of
one of the neurons, and only that neuron is activated by the stimulus
presentation; stimulus values that lie in between the preferred stimuli of
successive sensory neurons in the first layer do not elicit any activity in
the system. We can thus consider that any stimulus of interest is effectively
chosen within a discrete set of $L$ stimuli with values $x_{j}=j/L$, with
$j=1,\ldots,L$.

Each of these stimuli elicits a mean response
\begin{equation}
v_{i}(x_{j})=\tilde{A}W_{ij}\sim\mathcal{N}(0,R)
\label{Eq:uncorrelated-tuning-curve}%
\end{equation}
in neuron $i$ of the second layer. Here, the value of $\tilde{A}$ is chosen so
as to set the amplitude of the variations of $v_{i}$ to be equal to the
constant $R$ (analogously to Eq. (\ref{Eq:resource-limitation}) but for the
case of discrete stimuli). Geometrically, Eq.
(\ref{Eq:uncorrelated-tuning-curve}) represents a mapping from $L$ stimulus
values to a set of uncorrelated, random locations in the space of the
population activity (as illustrated in Fig. \ref{Fig:2}A for a two-neuron
population). In any given trial, however, the responses in the representation
layer are corrupted by noise (Fig. \ref{Fig:2}A). The ideal decoder (`ideal'
in the sense that it minimizes the mean error) interprets a single-trial
response as being elicited by the stimulus associated to the nearest possible
mean response (Fig. \ref{Fig:2}A). The outcome of this procedure can be
twofold: either the correct or an incorrect stimulus is decoded; in the latter
case, because the possible mean responses are arranged randomly in the space
of population activity (Fig. \ref{Fig:2}A and Eq.
(\ref{Eq:uncorrelated-tuning-curve})), errors of all magnitudes are
equiprobable. In other words, a model with narrow sensory tuning curves
results in a second-layer code that does not preserve distances among inputs,
and, consequently, the decoding error is either vanishing or, typically, on
the order of the input range (set to unity here). The mean error is  then
simply proportional to the probability with which the ideal decoder makes a mistake with a constant of proportionality of the order of the stimulus range.\textbf{[SIMONE to RAVA: 'The mean error can  then
simply be equated to'.'Equated' was not strictly mathematically correct, rather proportional with a O(1) constant of proportionality'?]}

In Methods, we provide a derivation of this quantity. In the case of low-error
coding, which interests us, we obtain the dependence of the probability of a
decoding error as a function of the various model parameters, as
\begin{equation}
P_{\text{error}}\approx\frac{L}{\sqrt{2\pi N}}\exp\left(  -{\log}\left(
{1+\frac{R}{2\eta^{2}}}\right)  {\frac{N}{2}}\right)  . \label{Eq:PGE}%
\end{equation}
The main dependence to note, here, is the exponentially strong suppression as
a function of the number of neurons in the second layer (Fig. \ref{Fig:2}B).
By contrast, the probability of error scales merely linearly with the size of
the stimulus space, $L$, as is expected in the low-error limit. This result
implies that it is possible to compress information highly efficiently in a
comparatively small representation layer ($N\ll L$) \textit{even though} the
code is completely random. The price to pay for the use of randomness is that
any error is likely `catastrophic' (on the order of the input range), but these large
errors happen prohibitively rarely. It is also worth noting that the rate of
exponential suppression depends on the variance of the noise, $\eta^{2}$, or,
more precisely, on the single-neuron signal-to-noise ratio, $R/\eta^{2}$
(where $R$ is the variance of the signal, Eq. (\ref{Eq:resource-limitation})).
In numerical simulations, we set $R=1$ and we vary $\eta^{2}$ to explore
different noise regimes. Interestingly, even when this signal-to-noise ratio
becomes small, i.e., when the noise in the activity of individual neurons is
comparable to modulations of their mean responses, the exponential suppression
of the probability of error remains valid, with a rate approximately equal to
$R/4\eta^{2}$ .



\subsection*{Compressed coding with broad tuning curves: trade-off between
local and global errors}

As we saw in the previous section, in the case of infinitely narrow tuning
curves the coding of a stimulus in a given trial is either perfect or
indeterminate; that is, any error is typically a global error, on the order of
the entire stimulus range. In the more general case of sensory neurons with
arbitrary tuning width, the picture is more complicated: in addition to
\textit{global} errors which result from the twisting and turning of the mean
response curve, the population code is also susceptible to \textit{local}
errors (Fig. \ref{Fig:3}A). This is because broad tuning curves in the sensory
layer partly preserve distances: locally, nearby stimuli are associated with
nearby points on the mean response curve; as a result, the coding of any given
stimulus is susceptible to local errors due to the response noise. As the
tuning width in the sensory layer, $\sigma$, decreases, two changes occur in
the mean response curve: it becomes longer (it `stretches out') and it
becomes more windy (Fig. \ref{Fig:1}C). Stretching increases the local
resolution of the code (because it allows for two nearby stimuli to be mapped
to two more distant points in the space of population activity), while
windiness increases the probability of global errors. This trade-off is
apparent when we plot the histogram of error magnitudes as a function of
$\sigma$:\ for larger values of $\sigma$, global errors are less frequent, but
local errors are boosted (Fig. \ref{Fig:3}B). Also noticeable, here, is that
the large-error tails of the histograms are flat, consistent with the
observation that global errors of all sizes are equiprobable. (Strictly
speaking, this happens if the stimulus has periodic boundary conditions, such
that, picking two random points, the probability that they are at a given
distance does not depend on the location of one or the other point.)

For a more quantitative understanding, we carried out an approximate
analytical calculation, in which (\textit{i}) we approximated the mean
response curve by a linear function locally and (\textit{ii}) we considered
that the distance between two segments of the curve containing the mean
response to two stimuli distant by more than $\sigma$ is sampled randomly.
Using these two assumptions, we obtained the MSE as a sum of two terms (see
Methods for mathematical details), as 
\begin{equation}
\varepsilon^{2}=\left\langle E^{2}\right\rangle _{W}\approx\left\langle
E_{l}^{2}\right\rangle _{W}+\left\langle E_{g}^{2}\right\rangle _{W}
\approx\frac{2\sigma^{2}\eta^{2}}{RN}+\frac{1}{\sigma\sqrt{2\pi N}}
\bar{\varepsilon}_{g}\exp\left(  {-\log}\left(  {1+\frac{R}{2\eta^{2}}
}\right)  \frac{N}{2}\right)  , \label{Eq:LvsG}
\end{equation}
where $\bar{\varepsilon}_{g}$ is a term of $\mathcal{O}\left(  1\right)  $
that depends upon the choice of stimulus boundary conditions (see Methods).
This expression quantifies the MSE for a `typical' network, obtained by
averaging over possible choices of synaptic weights, as indicated by the
brackets $\left\langle \cdot\right\rangle _{W}$. The first term on the
right-hand-side of Eq. (\ref{Eq:LvsG}) represents the contribution of local
errors, while the second term corresponds to global errors (Fig.
\ref{Fig:3}C). Their form can be intuited as follows. The variance of local
errors is proportional to $\sigma^{2}$ and inversely proportional to $N$, as
in classical models of population coding with neurons with bell-shaped tuning
curves (see, e.g., \cite{Zhang1999NeuronalBroaden}). Furthermore,
decreasing $\sigma$ stretches out the mean response curve, which increases the
local resolution of the code and explains the factor $\sigma^{2}$ in Eq.
(\ref{Eq:LvsG}). (The form of this first term can also be understood as the
inverse of the Fisher information
\cite[]{Seung1993SimpleCodes,Brunel1998MutualCoding}, which bounds the variance
of an unbiased stimulus estimator.) The second term on the right-hand-side of Eq. (\ref{Eq:LvsG})
is obtained as an extension of Eq. (\ref{Eq:PGE}): instead of considering the
probability that two mean response points are placed nearby, we consider the
probability that two segments of the mean response curve with size $\sigma$
each fall nearby. There are $1/\sigma$ such segments (since we have set the
stimulus range to unity), and this explains why the factor $L$ in Eq.
(\ref{Eq:PGE}) is replaced by a factor $1/\sigma$ in Eq. (\ref{Eq:LvsG}).
Importantly, the two terms in Eq. (\ref{Eq:LvsG}) are modulated differently by
the two parameters $N$ and $\sigma$. Depending upon their values, either local
or global errors dominate (Fig. \ref{Fig:3}C).

We tested the validity of Eq. (\ref{Eq:LvsG}): it agrees closely with results
from numerical simulations, in which we computed the MSE using a Monte Carlo
method and a network implementation of the ideal decoder (Fig. \ref{Fig:3}D
see Methods for details).  \textbf{[SIMONE: Clarification of discrepancy between MSE (text) and RMSE(plots): MSE when talking about error in general, while RMSE only when talking about a specific plot.]}(Henceforth we will refer to the MSE for the analytical computations, but we often plot its square root, the RMSE, such as to allow a direct comparison with the stimulus range. The illustrated quantity is always specified in the figure caption.) The non-trivial dependence is illustrated by the
observation that the MSE  may decrease or increase as a function of
$\sigma$, around a given value of $\sigma$, depending upon the value of $N$
(Fig. \ref{Fig:3}E). Furthermore, the strong (exponential) reduction in MSE
with increasing $N$ occurs only up to a crossover value that depends on
$\sigma$ (Fig. \ref{Fig:3}F); beyond this value, global errors disappear, and
the error suppression is shallower (hyperbolic in $N$, due to improved local
resolution). For small values of $\sigma$, the crossover values of $N$ are
larger and occur at lower values of the MSE.

As is apparent from Figs. \ref{Fig:3}D and E, for any value of $N$ there
exists a specific value of $\sigma=\sigma^{\ast}\left(  N\right)  $ that
balances the two contributions to the MSE such as to minimize it. This optimal
width can be thought as the one that stretches out the mean response curve as
much as possible to increase local accuracy but that stops short of inducing
too many catastrophic errors. The MSE is asymmetric about the optimal width,
$\sigma^{\ast}$: smaller values of $\sigma$ cause a rapid increase of the
error due to an increased probability of global errors, while larger values of
$\sigma$ mainly harm the code's local accuracy, resulting in a milder effect.
From Eq. (\ref{Eq:LvsG}), we obtain the dependence of the optimal width upon
the population size, as
\begin{equation}
\sigma^{\ast}\approx\left(  \frac{\bar{\varepsilon}_{g}}{4\eta^{2}}\sqrt
{\frac{N}{2\pi}}\right)  ^{1/3}\exp\left(  {-\log\left(  {1+\frac{R}{2\eta
^{2}}}\right)  \frac{N}{6}}\right)  , \label{Sigma_opt}%
\end{equation}
and the optimal MSE as a function of $N,$ as

\begin{equation}
\varepsilon^{2\ast}=\langle E^{2}(\sigma^{\ast})\rangle_{W}\approx\left(
\frac{\eta\bar{\varepsilon}_{g}}{\sqrt{2\pi}N}\right)  ^{2/3}\exp{\left(
-\log\left(  1+\frac{R}{2\eta^{2}}\right)  \frac{N}{3}\right)  }.
\label{MSE_opt}%
\end{equation}
Both these analytical results agree closely with numerical simulations (Figs.
\ref{Fig:4}A and B). Equation (\ref{MSE_opt}) and Fig. \ref{Fig:4}B show that
the optimal MSE is suppressed exponentially with the number of representation
neurons in the second layer. Thus, highly efficient compression of information
and exponentially strong coding also occurs when tuning curves in the sensory
layer are \textit{not} infinitely narrow. The rate of this scaling depends
upon the noise variance, $\eta^{2}$; in Figs. \ref{Fig:4}C and D, we
illustrate the dependence of $\sigma^{\ast}$ and $\varepsilon^*$ upon $N$ and $\eta^{2}$.

\subsection*{Compressed coding of multi-dimensional stimuli}

Real-world stimuli are multi-dimensional. Our model can be extended to the
case of stimuli of dimensions higher than one, but particular attention should
be given to the nature of encoding in the first layer---because sensory
neurons can be sensitive to one or several dimensions of the stimulus. In one
limiting case, a sensory neuron is sensitive to all dimensions of the
stimulus; for example, place cells respond as a function of the two- or
three-dimensional spatial location. Visual cells constitute another example of
multi-dimensional sensitivity, as they respond to several features of the
visual world; for example, retinal direction-selective cells are sensitive to
the direction of motion, but also to speed and contrast. In the other limiting
case, sensory neurons are tuned to a single stimulus dimension, and
insensitive to others. We will refer to these two coding schemes as
\textit{pure} and \textit{conjunctive}, following Ref.
\cite{Finkelstein2018OptimalBats} where they are examined in the context of
head-direction neurons in bats. The authors conclude that the relative
advantage of a pure coding scheme---with neurons that encode a single
head-direction angle---with respect to a conjunctive coding scheme---with
neurons that encode two head-direction angles---depends on specific
contingencies, such as the population size or the decoding time window.
Indeed, in a conjunctive coding scheme individual neurons carry more
information, but the population as a whole needs to include sufficiently many
neurons to cover the (multi-dimensional) stimulus space---a constraint which
becomes more restrictive as the number of dimensions increases.

%qualitative and quantitiative behavior of the two cases IN GENERAL
We generalized our model to include the possibility of $K$-dimensional
stimuli. For the sake of simplicity, we consider here only the two limiting
cases of \textit{pure} and \textit{conjunctive} coding in the \textit{sensory}
layer of our model (i.e., we do not discuss intermediate cases, in which a
given sensory neuron is sensitive to several but not all stimulus dimensions,
see Methods). In the model, furthermore, neurons in the
\textit{representation} layer receive random inputs from \textit{all} sensory
neurons; as such, the representation layer always embodies a conjunctive
coding scheme.

By extending the geometric picture (illustrated in Fig. \ref{Fig:1} for the
case of a one-dimensional stimulus), we can analyze differences in coding
properties between pure and conjunctive coding schemes; in Fig. \ref{Fig:5}A,
we illustrate the case of a two-dimensional stimulus. In this case, the mean
response of representation neurons corresponds to a mapping from a
two-dimensional stimulus space to a random `sheet' (a two-dimensional surface)
in the $N$-dimensional space of the population activity. In the \textit{pure
case}, the activity of a given sensory neuron is maximally modulated when the
stimulus varies along a particular dimension, the one to which the neuron is
sensitive. Variations of the stimulus along orthogonal directions have no
effect on the mean neural activity. As a result, neurons in the representation
layer, which compute a randomly weighted sum of the responses of sensory
neurons, are only mildly responsive to variations of the stimulus along
subsets of the stimulus dimensions. The resulting `response sheet' embedded in
$N$-dimensional space undergoes `folds' with creases along these directions of
mild sensitivity. By contrast, in the \textit{conjunctive case} the activity
of a sensory neuron is modulated by variations of the stimulus along any
direction. As a result, the `response sheet' that represents the joint mean
activity of neurons in the second layer undergoes (random) curvature along all
stimulus dimensions: rather than `folded', it looks like a `crumpled' sheet
(Fig. \ref{Fig:5}A).

This geometric picture offers an intuitive explanation of the behavior of the
mean decoding error in the two coding schemes. (For the corresponding
mathematical treatment, see Methods.) The local error is determined by how
much the `response sheet' is stretched out; in turn, the more the response
sheet is stretched out, the more it has to fold (or crumple) to fit in the
allowed range of neural activity. Folding allows for more a modest stretching
of the sheet than crumpling, and as a result the pure scheme incurs a larger
local error than the conjunctive scheme (see Eqs. (\ref{Eq:multi-local-pure})
and (\ref{Eq:multi-local-conj})). The global error is also different in the
two coding schemes; there are two mechanisms at play, here. First, in the pure
scheme, the folds of the surface imply that global errors occur between two
stimuli that differ in a single dimension, whereas, in the conjunctive scheme,
global errors occur between two stimuli that differ in an arbitrary number of
dimensions. Second, the \textit{total} variance of the tuning curve across the
stimulus space is fixed (and, in particular, set to the same value for the
pure and conjunctive schemes), but the signal-to-noise ratio which governs the rate of suppression with $N$ scales differently as a function of $K$. \textbf{[SIMONE to RAVA: `the \textit{total} variance of the tuning curve across the
stimulus space is fixed but it scales differently as a function of $K$'. Actually it is not the total variance which scales differently as a function of K, but rather the single-neuron signal-to-noise ratio governing the rate of scaling with N, as in one case is the SNR across a single dimension, while in the other case is the SNR across all stimulus space. ]}
Both mechanisms enhance the probability of global error in the pure scheme as
compared to the conjunctive scheme (compare Eq. (\ref{Eq:multi-global-pure})
and Eq. (\ref{Eq:multi-global-conj}) in Methods). Intuitively, this is because
a folded sheet has a larger surface area of contact with itself than a
crumpled sheet.

We illustrate these conclusions with numerical results in the case of a
three-dimensional stimulus ($K=3$), relevant to the data analysis we present
in the next section. In Fig. \ref{Fig:5}B, we illustrate the behavior of the RMSE as a function of $N$ and $\sigma$ for the pure and
conjunctive coding schemes. In order to quantify the relative advantage of one
scheme with respect to the other, we plot the ratio of the RMSE in the two
schemes as a function of $N$ and $\sigma$ (Fig. \ref{Fig:5}C). The resulting,
relatively intricate pattern, can be understood by considering different
regimes. If the population size is small, the pure scheme slightly outperforms
the conjunctive one;
\textbf{[SIMONE : R:"Naively, this is counter-intuitive as we expect that the pure case is bad if we have few neurons. Also, if global errors dominate, again the pure case should be worse.
So do you have a simple explanation for this statement?" S:"For simplicity, we compare just the global errors, as they are dominant. As N is small, the suppression is weak, so the advantage of conj scheme in the rate of scaling is minimal. Rather, it is dominant the influence of the prefactors, i.e., the number of uncorrelated regions. These are more in the conj scheme $(1/\sigma)^K$ rather then $K/\sigma$ (approximately) of the pure case, which makes the pure case slightly better. I avoided to explain this  because 1) One should have the formulas in front 2) The errors are large Propose: add `(due to a difference in the prefactors of the error probability, see Methods) "]} 
in this regime, global errors dominate and coding is poor overall. At larger values of
$N$, the contribution of local errors becomes non-negligible. If local errors
dominate (which occurs for large $N$ and sufficiently large $\sigma$), then
the conjunctive scheme outperforms the pure one, and the ratio of the RMSEs
approaches the theoretical prediction ($1/\sqrt{3}$). In the non-trivial
regime in which local and global errors are balanced (for large $N$ and
intermediate values of $\sigma$), the advantage of the conjunctive scheme is
further boosted. As explained above, this is due to a stronger suppression of
global errors as a function of $N$ in the conjunctive case. Finally, if
$\sigma$ becomes smaller than a crossover value that depends on the number of
sensory neurons, the latter no longer cover the stimulus space sufficiently
densely, and the conjunctive scheme breaks down; in this regime, thus, the
pure scheme is favored.

As illustrated in Fig. \ref{Fig:5}B, similar to the one-dimensional case there
exists in each of the two coding schemes an optimal value of the tuning curve
width, $\sigma$, which achieves a balance between local and global errors, and
it decreases with $N$. This dependence is somewhat different in the two coding
schemes (Fig. \ref{Fig:5}D), and contributes to the form of the suppression of
the RMSE in the two schemes (Fig. \ref{Fig:5}E). Both quantities, the optimal
tuning curve width and the RMSE, decrease more rapidly as a function of
$N\,\ $in the conjunctive scheme. This results from the fact that global errors
are suppressed more strongly with \thinspace$N$ in the conjunctive case (as
explained above), and therefore a smaller $\sigma$, yielding a lower local
error, is preferable. At the same time, the requirement that sensory neurons
cover the stimulus space yields a more stringent constraint on $\sigma$ in the
conjunctive scheme, yielding a bound on the extent of the regime of
exponential error suppression. 

\textbf{[SIMONE to RAVA: On the MSE-RMSE. While talking about analytical computation, we always use MSE, but in plots we show RMSE (allowing for a better comparison with stimulus range). I added a sentence when we first plot the RMSE while talking about the MSE. I would stick to the use of MSE when talking generically about error and about math, while using RMSE while talking explicitly about specific plots, like in this section.]}

\subsection*{Compressed coding in monkey motor cortex}

\label{Sec:data}

The activity of neurons in the primary motor cortex (M1) of monkey is
correlated to the location and movement of the limbs. Here, we consider
spatial tuning in the context of a `static task'
\cite[]{Kettner1988PrimateOrigins}. In this task, the monkey is trained to keep
its hand motionless during a given delay after having placed it at one of a
set of preselected positions on a three-dimensional grid labeled by the vector
$\mathbf{x}=\left(  x_{1},x_{2},x_{3}\right)  $. Tuning curves of
hand-position selectivity can be extracted from recordings of M1
\cite[]{Kettner1988PrimateOrigins,Wang2007MotorReaching}, and it has been
customary to model these as a linear projection of the hand position on a
so-called `preferred vector' or `positional gradient', varying linearly with a
combination of the spatial coordinates of the hand, $\mathbf{p}$, which thus
points in the direction of maximal sensitivity\cite[]{Wang2007MotorReaching}.
The tuning curve of neuron $i$ is then written as
\begin{equation}
v_{i}(\mathbf{x})=a_{i}+p_{1,i}x_{1}+p_{2,i}x_{2}+p_{3,i}x_{3}=a_{i}+\mathbf{p}_{i}\cdot\mathbf{x}. \label{Eq:CosTun}
\end{equation}
A recent study \cite[]{Lalazar2016TuningConnectivity} noted, however, that a
model of tuning curves that includes a form of irregularity yields an
appreciably superior fit to the simple linear behavior of Eq. (\ref{Eq:CosTun}
). This more elaborate model \cite[]{Lalazar2016TuningConnectivity} bears
similarity with our model of irregular tuning curves, and this naturally led
us to ask about potential coding advantages that a complex coding scheme may
afford in M1.

To be more specific, one can interpret the first layer in our network featured
with neurons with three-dimensional Gaussian tuning curves, as representing
neurons in the parietal reach area (or premotor area), which are known to
display spatially localized tuning properties
\cite[]{Andersen1985EncodingNeurons}. This population of neurons projects to a
smaller population of M1 neurons which display spatially extended and
irregular tuning profiles. In fitting our model to recordings from M1 neurons
\cite[]{Lalazar2016TuningConnectivity}, we considered the arrangement of stimuli
used in the experiment, namely 27 spatial locations arranged in a
$3\times3\times3$ grid fitting in a 40 cm-high cube. We then followed a
previous fitting method
\cite[]{Lalazar2016TuningConnectivity,Arakaki2019InferringCurvesb}:\ given the
diversity of the irregular tuning curves in the population we did not aim at
fitting individual tuning curves; instead, we allowed for randomly distributed
synaptic weights (as in our original model) and we fitted a single parameter,
the width of the tuning curves in the first layer, $\sigma$. The fit was aimed
at reproducing specific summary statistics of the data referred to as
\textit{complexity measure} (discrete version of the Lipschitz derivative that
quantifies the degree of smoothness of a curve, see Methods and 
\cite{Lalazar2016TuningConnectivity}). The complexity measure varies from
neuron to neuron, and we chose $\sigma$ so as to minimize the
Kolmogorov-Smirnov distance between the distribution implied by our model and
the one extracted from the data. While our model is somewhat simpler than a
model of irregular M1 tuning curves employed previously
\cite[]{Lalazar2016TuningConnectivity}, it yields comparable fits. In addition
to fitting the population of tuning curves, we extracted from the data a
quantification of the noise in the response of individual neurons. For each
recorded neuron, we computed the variance of the signal as the variance,
across different stimuli, of the mean firing rate (left hand side of Eq.
(\ref{Eq:resource-limitation})). Then, we estimated the variance of the noise
by averaging the trial-to-trial variability of responses to the same stimulus.
These two quantities allowed us to define a signal-to-noise ratio for each
neuron of the population (see Eq. (\ref{Eq:snr-data}) in Methods). As in
simulations we fixed the variance of the signal for each neuron to a constant
value, we modeled the heterogeneity of the signal-to-noise ratio as a
heterogeneous noise variance.

With a neural response model in hand, we can evaluate the coding performance;
to do so, we consider a finer, $21\times21\times21$ grid of spatial locations
as our test stimuli. We quantify the merit of a compressed code making use of
irregular tuning curves by computing the MSE, $\varepsilon_{\text{irr}}^{2}$,
and comparing the latter with the corresponding quantity in a coding scheme
with the smooth tuning curves defined in Eq. (\ref{Eq:CosTun}), $\varepsilon
_{\text{lin}}^{2}$. We plot our results in terms of the `mean percent
improvement', $\Delta\varepsilon\equiv\left(  \varepsilon_{\text{lin}%
}-\varepsilon_{\text{irr}}\right)  /\varepsilon_{\text{lin}}$ . $\Delta
\varepsilon$ is positive when irregularities favor coding, and is at most
equal to unity (in the extreme case in which irregularities allow for
error-free coding).

We explore the performance of the two coding schemes for different values of
the parameters $N$ and $\sigma$, first in an ideal case in which all neurons
have the same noise variance (Fig. \ref{Fig:6}A). We note the existence of a
crossover value of $N$, $N^{\ast}$. When $N<N^{\ast}$, small values of
$\sigma$ induce prohibitively frequent global errors in the compressed
(irregular) coding scheme, and linear (smooth) tuning curves are more
efficient. For $N>N^{\ast}$, however, irregularities are always advantageous,
and the more so the smaller the value of $\sigma$. Because global errors are
suppressed exponentially with $N$, $N^{\ast}$ typically takes a moderate value
which depends on the magnitude of the noise; the larger the noise, the larger
$N^{\ast}$. Figure \ref{Fig:6}B illustrates this noise-dependent behavior of
the crossover population size, for the best-fit value of $\sigma$ ($\approx23$).

Next, for a more realistic modeling of M1 neurons, we analyzed the performance
of a model in which each neuron's noise variance is extracted from the data
(Figs. \ref{Fig:6}C and D). Noise variances in the population are
heterogeneous, with a fraction of neurons exhibiting low signal-to-noise
ratios (Fig. \ref{Fig:6}C, inset). For each value of $N$, we sampled eight
different pools of $N$ neurons from the population, and we averaged the
corresponding mean percent improvement, $\Delta\varepsilon$. We found, again,
that the relative merit of compressed coding (with irregular tuning curves)
grows with the population size; interestingly, when compressed coding becomes
advantageous ($\Delta\varepsilon>0$ in Fig. \ref{Fig:6}C), the MSE is still
appreciable (Fig. \ref{Fig:6}D). This means that even though local and global
errors are balanced, both occur with non-negligible likelihood. $\Delta
\varepsilon$ continues to grow with $N$ until global errors are suppressed;
beyond this second crossover value, $N_{\text{local}}$, $\Delta\varepsilon$
saturates because in both coding schemes (with irregular and linear tuning
curves) local errors dominate. Correspondingly, the MSE scales differently for
$N$ above or below $N_{\text{local}}$. When $N<N_{\text{local}}$ the MSE
decreases exponentially with $N$, due to the suppression of global errors,
while when $N>N_{\text{local}}$, the suppression of the MSE is hyperbolic in
$N$, reflecting the behavior of local errors only (Fig. \ref{Fig:6}D). This
second crossover occurs at $N_{\text{local}}\approx100$, a figure comparable
to the number of neurons that control individual muscles in this specific
task, as estimated from decoding EMG signals from individual muscles from
subsets of M1 neurons \cite[]{Lalazar2016TuningConnectivity}.
\subsection*{Dimensionality of a compressed neural code }
\label{SuSe:Geo}
We introduced the geometrical interpretation of a neural code as a map between a set of stimuli and an ensemble of points in the space of mean population activity. In the case of a continuous $K$-dimensional stimulus space and smooth tuning curves, the code produces a $K$-dimensional surface embedded in the $N$-dimensional space of neural activities, which is often referred to as `neural response manifold'\cite[]{Seung2000ThePerception,Gallego2017NeuralMovement}, implicitly assuming a  local homeomorphism to a Euclidean space. In the previous sections we analyzed how the geometrical properties of the response manifold affects the coding performance of the population. In this section we aim to enrich this picture by characterizing quantitatively the `dimensionality' of the manifold we considered, and to give another interpretation, through this measure, of the results of the previous sections. We will focus, for the sake of simplicity, on the one-dimensional case.

The complex tuning curves of the representation neurons, serving as coordinates of the resulting manifold, are samples from a  Gaussian process (see Methods); therefore, the manifolds we obtain belong to the class of Gaussian manifolds \cite[]{Lahiri2016RandomManifolds}. As the stimulus is one-dimensional, the manifold of mean population activity occupies a one-dimensional subspace (i.e., it is a curve); nevertheless, we showed in Fig. \ref{Fig:1}C that its `complexity' changes as a function of $\sigma$. In order to quantify this complexity, we start by measuring how the neural responses are `spread' in the $N$-dimensional space through the spectrum of the eigenvalues of the covariance matrix of the neural responses, corresponding to the variance carried by the principal components in PCA (Fig. \ref{Fig:7}A). The resulting spectrum exhibits a band-pass structure, as it is flat up to a cut-off value, which increases by decreasing $\sigma$, and then falls quickly to 0. This implies that neural responses are equally spread across a number of principal axes, occupying a lower dimensional subspace of the $N$-dimensional space of neural activities; by decreasing $\sigma$, we increase the number of these principal axes, up to the limit of $\sigma \rightarrow 0 $, when the responses spread across all the $N$ dimensions, and the spectrum is completely flat.

Following \cite{Gao2017AMeasurement}, we can extract a  measure of the `complexity' of these manifolds based on the spectrum of the covariance matrix, by defining the  \emph{intrinsic dimensionality} as the eigenvalues' participation ratio: $d_i = (\sum_{i=1}^N\mu_i)^2/\sum_{i=1}^N\mu_i^2$. This measure yields indeed a value close to $N$ in the case of $\sigma \rightarrow 0 $, denoting an infinitely tangled manifold, and it is inversely proportional to $\sigma$, leading to  values close to $1$ in the case of broad tuning curves (Fig. \ref{Fig:7}B).  With this definition in our hands, it is natural to investigate the geometrical properties of the manifold produced by our coding scheme at the optimal value of $\sigma$. In Fig. \ref{Fig:7}C we computed the fraction of dimensions (i.e., the intrinsic dimensionality divided by the number of neurons) occupied by the optimal neural manifold, for a fixed noise level, as a function of the population size. When $N$ is low, the manifold is forced to lie on a low-dimensional subspace in order to avoid global errors. As $N$ increases, the manifold can occupy a larger fraction of the available dimensions, increasing its length and consequently the local accuracy, but still yielding a low number of global errors. This analysis offers an example, through a simple mechanism, of how the optimal dimensionality of a neural code is a quantitative question, which depends upon the population size and the variance of the noise.

\subsection*{Compressed coding with noisy sensory neurons}

\label{SuSe:In}

Until now, we have considered the presence of response noise only in
second-layer neurons. In this case, as long as sensory neurons are tiling the
stimulus space (i.e., unless there are regions in stimulus space in which
sensory neurons are unresponsive), stimuli are encoded with perfect accuracy
in the activity of the first layer, and the MSE inferred from activity in the
second layer can be made arbitrarily small for sufficiently large
\thinspace$N$. If sensory neurons are also noisy, then they represent stimuli
only up to some degree of precision. Furthermore, because of the (dense)
projections from the first to the second layer of neurons, independent noise
in sensory neurons induces correlated noise in representation neurons. If the
independent noise in sensory neurons is Gaussian with variance equal to
$\xi^{2}$, then the covariance of the noise in the second layer becomes
$\bm{\Sigma}=\eta^{2}\mathbf{I}+\xi^{2}\mathbf{WW^{T}}$. Thus, sensory noise
affects the nature of the `representation noise', and it is natural to ask how
this changes the population coding properties.

As we shall show, in the compression regime ($N\ll L$) on which we focus, the
kind of correlations generated by noise in the sensory layer have a negligible
effect on the coding performance. Obviously, the introduction of sensory noise
degrades coding, so the comparison of the noisy and noiseless systems is not
very telling. Instead, we compare population coding in the presence of the
full noise covariance matrix, $\bm{\Sigma}$, and in the presence of a diagonal
noise covariance matrix with matched diagonal elements. Since synaptic weights
are realizations of a Gaussian random variable, the matrix $\mathbf{WW^{T}}$
follows a Wishart distribution with mean the identity matrix (see Methods);
therefore, the average variance-matched diagonal covariance matrix is written
as $\bm{\Sigma_{\text{ind}}}=\left(  \eta^{2}+\xi^{2}\right)  \mathbf{I}.$
%\textbf{[RAVA TO SIMONE: One important subtlety/question -- we should probably
%covariance matrix in the case of each full matrix, rather than the average
%diagonal matrix. This is because the non-averaged matrix will yield better
%coding. So, by considering the average diagonal matrix we are `artificially'
%making coding in the diagonal (independent) case worse than it actually is!]}
\textbf{[SIMONE: Simulations with W-dependent diagonal and average diagonal noise leads to the same results. The variance of the diagonal elements is 1/L, multiplied by the noise we considered (less than 1), leads to a very weakly anisotropic Gaussian noise, which can be fairly assumed to be isotropic. Also, I would use this comparison because it facilitates the analytic treatment and leads to homogeneous noise variance, which is the regime we treated previously. ]}
(The correct comparison is between the full covariance matrix and its diagonal counterpart, leading to anisotropic variance which depends on the specific realization of the random weights. As fluctuations of $\mathbf{WW^{T}}$ around the identity are of order $1/L$, simulations with the average diagonal matrix leads to the same results in the regime of noise we considered.)
The latter is equivalent to a network with noiseless sensory neurons, but
enhanced independent noise in representation neurons, with variance
$\tilde{\eta}^{2}\equiv\eta^{2}+\xi^{2}$. In numerical studies, we observe,
first, that the MSE depends only weakly on the noise correlations, as a
function of $\sigma$. This behavior obtains because noise correlations
primarily affect local errors, not global errors. (As noise correlations
reduce the noise entropy---they `shrink the cloud of possible noisy
responses'---with respect to the independent case, one expects that
correlations reduce the probability of occurrence of global errors. Numerical
simulations however indicate that this effect is quantitatively negligible.)

The picture is different in the case of local errors, which can be either
suppressed or enhanced by correlated noise \cite[]{daSilveira2021ThePopulations}. We can show analytically that, here, local errors are enhanced; from a
perturbative expansion of the inverse covariance matrix (see Methods for
details), we obtained the local contributions to the MSE as
\begin{equation}
\varepsilon_{l}^{2}=\varepsilon_{l,\text{ind}}^{2}\left(  1+\frac{N\xi^{2}%
}{L\tilde{\eta}^{2}}-\frac{N\xi^{4}}{L\tilde{\eta}^{4}}+\ldots\right)
\label{Eq:IN}%
\end{equation}
in orders of $\xi^{2}/\tilde{\eta}^{2}$, where $\varepsilon_{l,\text{ind}}%
^{2}$ is the corresponding quantity calculated for the variance-matched
covariance matrix $\bm{\Sigma_{\text{ind}}}$ rather than the full covariance matrix
$\bm{\Sigma}.$ 

From Eq. (\ref{Eq:IN}), it appears that the effect of noise correlations on the MSE
is deleterious but scales only weakly with $N/L\ll1$. We checked this behavior
numerically (Fig. \ref{Fig:8}A), and found a good match with the analytical
result. We also compared the impact of different values of $\xi^{2}$, while
keeping the effective noise variance, $\tilde{\eta}^{2}$, fixed (i.e., varying
the relative contribution of input noise and output noise). Both Eq.
(\ref{Eq:IN}) and Fig. \ref{Fig:8}B indicate that there exists a regime in
which increasing $\xi^{2}$ in fact mitigates the deleterious effect of the
correlated noise (this is seen in Eq. (\ref{Eq:IN}) as a partial cancellation
of the second- and fourth-order terms).

Finally, we ask whether the impact of the noise correlation results
specifically from the form with which sensory noise invests it. To answer this
question, we examine a network with noiseless sensory neurons, but in which
representation neurons exhibit correlated Gaussian noise, with a covariance
matrix that has the same statistics as those of $\bm{\Sigma}$, but in which the
form of correlations is not inherited from the network structure through the
synaptic matrix $\mathbf{W}$; specifically, we consider a random covariance
matrix, $\bm{\Sigma_{\text{rand}}}=\eta^{2}\mathbf{I}+\xi^{2}\mathbf{XX^{T}}$,
where $X_{ij}\sim\mathcal{N}(0,1/L)$. In this case, noise correlations
\textit{suppress} the MSE as compared to the independent case (with
$\bm{\Sigma_{\text{ind}}}$), because the `cloud of possible noisy responses' is
reoriented randomly with respect to the curve of mean responses. Analytically,
the analog of Eq. (\ref{Eq:IN}) for the case of a covariance matrix
$\sigma_{\text{rand}}$ (instead of $\sigma$) 
%\textbf{[RAVA\ TO\ SIMONE:\ Correct? SIMONE: No, it was rand instead of ind]} 
is similar, but skips the lowest-order,
deleterious term:
\begin{equation}
\varepsilon_{l,\text{rand}}^{2}\approx\varepsilon_{l,\text{ind}}^{2}\left(
1-\frac{N\xi^{4}}{L\tilde{\eta}^{4}}\right)  . \label{Eq:Rand}%
\end{equation}
This result, as well as numerical simulations (Fig. \ref{Fig:8}B), demonstrate
that generically coding is improved by random noise correlations, and that
this improvement increases with $N$ and with the relative contribution of $\xi^{2}$. 
\textbf{[SIMONE: `increases with $\xi^2$' .Stated like this, it seems that increasing input noise improves coding, but it also increases $\tilde \eta$ . I would add ' with the relative contribution of'.]}
In sum, noise
correlations in representation neurons are deleterious if they are inherited
from noise in sensory neurons---yet, the effect is quantitatively modest.

\section{Discussion}

\textbf{Summary.} We analyzed the coding properties of neural populations
beyond classic models of tuning curves, by considering irregular response
profiles resulting from random feedforward connectivity. Our model can
interpolate between an irregular coding scheme, highly efficient but prone to
catastrophic errors, and a smooth one, more robust in the face of noise.
Optimality is achieved at an intermediate level of irregularity, which depends
on the population size and on the variance of the noise. In the optimal code,
the mean error is suppressed exponentially with population size. As a result,
irregular neural codes allow for a strong compression of stimulus information
from a large, first layer of neurons to a small, second layer. We extended
these results to the case of multi-dimensional stimuli, more intricate because
sensory neurons can exhibit various degrees of mixed selectivity; we considered
in particular a pure coding scheme, in which sensory neurons are sensitive to
a single stimulus dimension, and a conjunctive coding scheme, in which sensory
neurons are sensitive to all stimulus dimensions. We examined the relative
advantage of one scheme with respect to the other, a question explored
recently elsewhere also
\cite[]{Finkelstein2018OptimalBats,Harel2020OptimalConstraints}, and elucidated
its dependence on the number of representation neurons and on the tuning
parameters. These analyses enabled us to revisit data from M1 neurons in
monkey \cite[]{Lalazar2016TuningConnectivity} and to discuss the benefits of an
irregular code in the context of the representation of hand position. Finally,
we broadened the picture of compressed coding by considering input noise, in
addition to output noise, and by analyzing the dimensionality of population
activity in the case of an optimal code. This dimensionality is larger than
the dimensionality of the stimulus, but smaller than the population size, so
that it allows for an efficient use of the space of population activity while
avoiding the proliferation of global errors.

`\textbf{Exponentially strong' neural population codes.} Our results on the
exponential scaling of the mean error with the population size are similar to
results obtained in the context of the representation of position by grid
cells
\cite[]{Fiete2008WhatLocation,Sreenivasan2011GridComputation,Mathis2012ResolutionNeurons,Wei2015ACells}. According to the terminology adopted in this literature the random
compressed coding presented here is an `exponentially strong' population code.
Grid cell-tuning is a particular instance of exponentially strong codes making
use of periodicity; the model presented here offers another example, in which
tuning curves are random. In fact, the notion of an exponentially strong code
predates work in computational neuroscience, as Shannon, already in 1949
introduced it in the context of a communication system for a continuous
quantity \cite[]{Shannon1949CommunicationNoise}. In his framework, a sender maps
a `message' (a continuously varying quantity analogous to our stimulus) into a
`signal' (a higher-dimensional continuous quantity analogous to the output of
our representation layer) which is then decoded by a receiver. The specific
illustration he provides is that of a one-dimensional message mapped into a
higher-dimensional signal (Fig. 4 in Ref. \cite{Shannon1949CommunicationNoise}
), analogous to the mapping illustrated in Fig. \ref{Fig:1}C; this mapping
corresponds to a curve that  wraps around in a higher-dimensional space.
Shannon argues that an efficient code is obtained by stretching this curve to
make it as long as possible up to the point at which the winding and twisting
causes the curve to pass too close to itself, thereby generating catastrophic errors.

Yet Shannon went further, and showed that such a code need not to be carefully
designed. His calculation corresponds, in our framework, to the case of
infinitely narrow tuning curves in the sensory layer (Fig. \ref{Fig:2}): he
demonstrated that, in this scenario, it is possible to send a set of discrete
messages, with an error that is suppressed exponentially in the dimensionality
of the signal. Our work proposes an extension of this `fully random'
scenario:\ by varying the width of tuning curves in sensory neurons, $\sigma$,
one can modulate the smoothness of the mapping and trade off global errors
with local errors. In this more general, `correlated random' scenario, it is
optimal to choose a non-vanishing value of $\sigma$ which depends on the
population size and other model parameters.

\textbf{Coding with complex tuning curves.} A large body of literature has
addressed the problem of coding low-dimensional stimuli in populations of
neurons with simple tuning curves. The most common assumption is that of
bell-shaped tuning curves; these are often chosen to model sensory coding in
peripheral neurons. Various studies set in this context discussed the shape of
optimal tuning curves as a function of population size and stimulus
dimensionality \cite[]{Zhang1999NeuronalBroaden}, stimulus geometry
\cite[]{Montemurro2006OptimalVariables}, and the time scale on which coding
operates \cite[]{Bethge2002OptimalFails,Yaeli2010Error-basedNeurons}. More
recent work analyzed the influence of a (non-uniform) prior distribution of
stimuli on the optimal arrangement and shapes of tuning curves across a
population of neurons; a particular prediction is that the tuning-curve width
is narrower for neurons with a preferred stimulus over-represented in the
prior
\cite[]{Wei2012EfficientInference,Ganguli2014EfficientPopulations,Yerxa2020EfficientStimuli}
. A separate direction of study focused on the effects of heterogeneity in the
tuning-curve parameters on the coding performance
\cite[]{Wilke2002RepresentationalPopulations,Shamir2006ImplicationsCoding,Fiscella2015VisualNeurons,Berry2019FunctionalCode}


Our study falls in this line of work, but it presents two important
differences:\ (\textit{i}) we consider a family of irregular tuning curves (to
be contrasted with simpler tuning curves, such as bell shaped or monotonic)
and (\textit{ii}) we consider downstream neurons rather than peripheral ones.
To be more specific about point (\textit{i}), we consider tuning curves
resulting from a feedforward network with random synaptic weights. The
assumption of random connectivity yields a `benchmark model'; similar
comparisons with benchmark random models have been used previously in
examining information processing among layers of neural networks
\cite[]{Barak2013TheTrade-off,Babadi2014SparsenessRepresentations,Litwin-Kumar2017OptimalConnectivity}. In our case, the irregularity of tuning curves makes the response of any
single neuron highly ambiguous; the resulting code is thus distributed, and
the neural population as a whole is viewed as the relevant unit of computation
\cite[]{Saxena2019TowardsDoctrine}.

Distributed codes have been argued to come with high capacity. An early
example was developed in the context of face coding in the superior temporal
sulcus of monkey \cite[]{Abbott1996RepresentationalMonkeys}. Data analysis
indicated that single-neuron sensitivity was heterogeneous and uninformative,
but the number of distinguishable face stimuli grew exponentially with the
population size. Our work provides an example of a random distributed code for
continuous stimuli, which exhibits similar scaling properties. The main
difference is that, in the case of continuous stimuli, the identity of a
stimulus is ill-defined, what matters are the distances between pairs of
stimuli. In other word, both the probability of occurrence of an error and its
magnitude matter. The requirement of minimizing the mean squared error then
yields a particular coding scheme that balances small (local) and large
(global) errors.

Regarding point (\textit{ii}), we recall that, to date, `efficient coding'
models of neural coding have addressed peripheral or `receptor' neurons, i.e.,
neurons activated directly by a physical stimulus. Our work departs from this
framework, in that it focuses on coding in a population of neurons downstream
from receptor neurons. In this case, it is not possible to optimize the
properties of one population without considering those of the other
population. In particular, in our approach we optimize the coding scheme in
receptor (sensory) neurons subject to constraints on the activity of
downstream (representation) neurons. This way of thinking provides a different
angle on the rationale for an optimal code.

\textbf{Geometry and dimensionality of population responses.} In the past
decade, the progress in experimental methods has allowed for the recording of
neural populations on a large scale
\cite[]{Cunningham2014DimensionalityRecordings,Saxena2019TowardsDoctrine}. In an
effort to interpret the way in which information is represented in population
activity, various approaches have been focusing on the geometric properties of
ensembles of population responses to a battery of stimuli
\cite[]{Fusi2016WhyCognition,Gallego2017NeuralMovement,Stringer2019HighCortex,Kobak2019State-dependentCortex}
. Points in a high-dimensional space, each corresponding to the neural
population response to a stimulus, are often interpreted as being located on a
manifold which describes the space of possible population activity.
Quantifying the geometry, and more specifically the dimensionality of this
manifold, offers a characterization of neural population activity. This
geometric element is eminently relevant in our work, too, where the
distribution of coding errors depends directly on the geometry of the
population activity in a representation layer, that results from the
properties of neural responses in a sensory layer. 

A specific geometrical question is that of the dimensionality of the
population response in the representation layer. In Sec. \ref{SuSe:Geo}, we
showed that the spectrum of the covariance of the population activity in the
representation layer, across the stimulus space, comes with a band-pass
structure; by decreasing the width of tuning curves in the sensory layer, the
band-pass profile acquires additional modes.
\cite{Stringer2019HighCortex} discussed a similar picture in analyzing
recordings from a large population of visual neurons responding to a large,
but discrete, set of images. In their case, the spectrum of the covariance
matrix of population responses exhibits an algebraic (power-law) tail, and the
authors argue that this property allows a high-dimensional population activity
while retaining smoothness of the code. Our work presents a different, and
more elementary, mechanism by which a large number of modes can be
accommodated by the population activity (while retaining smoothness). The
non-trivial point, in our case, is that it is not beneficial for coding to be
poised in the limiting case in which the number of modes is maximal but the
code becomes singular (non-smooth). The reason is that, in this limit, global
errors proliferate. The optimal dimensionality of the response manifold lies
at an intermediate value at which intersections of the manifold with itself
are rare and local and global errors are balanced (Fig. \ref{Fig:7}).

\textbf{Compressed sensing.} We studied a network in which the information
encoded in a high-dimensional activity pattern is compressed into the activity
of a comparatively small number of neurons, a setting which exhibits analogies
with the one of compressed sensing
\cite[]{Candes2006Near-optimalStrategies}.
Compressed
Sensing is a signal-processing approach for reconstructing $L$-dimensional
signals, which are $K$-sparse in some basis (i.e., they can be expressed as
vectors with only $K$ non-vanishing elements) from a $N$ linear and noisy
measurements of the original signals, with $K\ll L$ and $N\ll L$
\cite[]{Donoho2006CompressedSensing}. In our study, the low dimensionality of
the stimulus, $x$, implies sparsity of the $L$-dimensional activity of the
sensory layer, as long as the tuning curves in the sensory are not too wide.
\textbf{[}(but see \cite{Baraniuk2009RandomManifolds} for more details)
\textbf{SIMONE TO RAVA: What do you mean by `Why does `this' appear here'? The paper extends the result of CS to signals which are not explicitly sparse (at least, not with a linear change of basis), but rather lie on a low-dimensional manifold, analog to our case where there is a low-dimensional variable which generates the signal through a non linear process. Therefore some of the results of CS are still valid, in particular the fact that  a logartihmic number of Random Projections preserve distances between points. That's why I would avoid the sentence  'as long as the tuning curves in the sensory are not too wide.', because yes, in that case the signal is not strictly sparse, but still this paper says that  some results of CS are valid.(Actually, their result invoke a notion of `curvature', so the comprssibility of the data increases as the width increases.)} 

A central result in the field of compressed sensing is that random
measurements achieve near-optimal results. Furthermore, for this to obtain,
the number of measurements scales with
$K$  and only logarithmically with the dimensionality of the signal $N>\mathcal{O}\left(  K\log\left(  L/K\right)
\right) $
\cite[]{Candes2006Near-optimalStrategies,Baraniuk2008AMatrices}. In effect, in
our network the representation layer operates a limited number of random
measurements from the sensory layer. And we obtain an analog scaling form by
inverting Eq. (\ref{Eq:PGE}): the number of random projections, $N$, necessary
to decode $L$ different stimuli with negligible error scales logarithmically
with the number of stimuli. We note, however, that our framework differs from
that of compressed sensing as the objective is to decode the identity of the
stimulus rather than a high-dimensional signal vector (in our case, the
activity pattern of the sensory layer).

\textbf{Encoding vs. decoding.} In our study, we focused exclusively on the
properties of encoding in a neural population. For this aim, throughout we
assume an ideal decoder; in principle, this is not a limitation:\ we show in
Methods that an ideal decoder can be implemented in a simple, two-layer neural
network. The first layer computes a discretized approximation of the posterior
distribution over stimuli, and the second layer computes the mean of this
distribution, in such a way as to minimize the MSE. Furthermore, all the
operations carried out by this two-layer network---linear filtering,
non-linear transfer, and normalization---are plausible biological operations
\cite[]{Deneve1999ReadingObservers,Kouh2008AOperations,Carandini2012NormalizationComputation}. The parameters involved, however, have to be chosen with the knowledge of
the tuning curves and noise model.

One can ask whether biologically plausible learning rules can result in a
decoder than approximates closely the ideal one. A closely related questions
has been examined by  \cite{Bordelon2020SpectrumNetworks}, who
analyzed how the generalization error in a deep neural network trained with
gradient descent depends on the number of training samples and on
the Fourier modes of the target function
\textbf{[SIMONE to RAVA:Strictly speaking, it is not restricted to Fourier modes, as their theory generalize to any eigenfunction decomposition of a function belonging to a RKHS. But for the sake of simplicity, maybe talking about Fourier modes (which is a special case) is more immediate?]}. 
\cite{Bordelon2021PopulationBias} find that
learning the high-frequency Fourier components of the target function requires
a larger number of training samples, as compared to learning the low-frequency
components.
%[\textbf{RAVA\ TO\ SIMONE:\ Is this correct?\ It was not clear.]}.
Similarly, in the context of our network one expects that learning a decoder
in the case of narrow tuning curves in the sensory layer is more laborious
than in the case of broad tuning curves. Furthermore, noise in the training
samples may hamper learning severely in the presence of global errors.
Broadly, one can ask to what extent our results may be modified if the
decoding is carried out by a decoder different from the ideal one, for example
by a decoder obtained through adequately chosen learning rules. We leave the
study of this question for future work.

\section{Methods}

\label{Se:Me} Throughout the discussion, bold letters denote vectors
$\mathbf{r} = \{r_{1},r_{2},...,r_{N} \}$. $\left\|  \mathbf{r} \right\|
_{2}^{2} = \sum_{i} r_{i}^{2}$ represents the $L_{2}$ norm. Capital bold
letters $\mathbf{W}$ denote matrices. Numerical simulations and data analysis
were done using a custom code written in Julia
\cite[]{Bezanson2017Julia:Computing}.

\subsection*{Model description: one-dimensional stimulus}

\textbf{Network definition and constraints.} The first, sensory layer is made
of $L$ neurons, encoding a continuous scalar stimulus $x \in[0,1]$, with
Gaussian tuning curves.
%\footnote{In the following, all the computations
%and simulations are done for a one-dimensional linear stimulus encoded byGaussian tuning curves. At the same time, we will often assume translational
%invariance; this will unavoidably introduce edge effects. A more rigorous way
%would be to consider a circular stimulus and von Mises tuning curves in the
%first layer:
%\[
%u_{j}(x) = A exp\left(  \mathcal{K} cos\left(  2\pi\left(  x-c_{j}\right)
%\right)  \right)  .
%This complicates the form of the correlation function and it would require a
%modification of the error function. Anyway, we considered regimes where
%$\mathcal{K}$ is large and the von Mises function can be approximated locally
%as a Gaussian with width $\sigma^{2} = 1/\mathcal{K}$. In the regimes of
%$\sigma$ considered in the simulations, and considering that $L$ is very
%large, the edge effects are small and simulations with circular stimulus did
%not change qualitatively the results. In Fig. \ref{Fig:3}B only, for
%visualization purposes, we plotted the result for a circular stimulus.}
The firing rate of neuron $j$ as a function of $x$ is given by
\begin{equation}
u_{j}(x) = A\exp\left(  -\frac{(x-c_{j})^{2}}{2\sigma^{2}}\right)  ,
\tag{\ref{Eq:tuning-curve-layer1} restated}%
\end{equation}
where $c_{j}$ is the preferred stimulus of neuron $j$, $\sigma$ is the tuning
width, and $A$ is a gain which will be chosen accordingly. The preferred
stimuli are evenly spaced, $c_{j}= j/L$. These neurons are all-to-all
connected to the $N$ representation neurons, with i.i.d Gaussian weights,
$W_{ij} \sim\mathcal{N}(0,1/L)$. The response of representation neuron $i$ is
therefore obtained as
\begin{equation}
v_{i}(x) = \sum_{j=1}^{L} W_{ij}u_{j}(x). \tag{\ref{Eq:tuning-curve-layer2}
restated}%
\end{equation}
The gain $A$ is chosen such to keep constant the variance of the responses across stimuli, averaged over different network realizations. This constraint reads
\begin{equation}
\begin{split}
R  &  = \left\langle \int_{0}^{1} dx \left[  v_{i}\left(  x\right)  -\int%
_{0}^{1}dx^{\prime} v_{i}\left(  x^{\prime}\right)  \right]  ^{2}
\right\rangle _{W}\\
&  = \left\langle \int_{0}^{1} dx v_{i}(x)^{2} - \left(  \int_{0}^{1} dx
v_{i}(x)\right)  ^{2} \right\rangle _{W}\\
&  = \left\langle \sum_{j,j^{\prime}} W_{ij}W_{ij^{\prime}}\left(  \int%
_{0}^{1} dx u_{j}(x)u_{j^{\prime}}(x)\right)  - \sum_{j,j^{\prime}}
W_{ij}W_{ij^{\prime}}\left(  \int_{0}^{1} dx u_{j}(x)\right)  \left(  \int%
_{0}^{1} dx u_{j^{\prime}}(x)\right)  \right\rangle _{W}\\
&  = \int_{0}^{1} dx u_{j}\left(  x\right)  ^{2} - \left(  \int_{0}^{1} dx
u_{j}\left(  x\right)  \right)  ^{2} ,\label{Eq:resource-constraint-ext}%
\end{split}
\end{equation}
where $\langle\cdot\rangle_{W}$ indicates the average over the distribution of
synaptic weights. Since the synaptic weights are i.i.d.
Gaussian, $\langle W_{ij}W_{ij^{\prime}}\rangle_{W} = \frac{1}{L}%
\delta_{jj^{\prime}}$. Here and in following calculations, we use the
approximation for the Gaussian integral \textbf{[MIRKO: Express the result in terms of error functions and then use the approximation? S: I don't think is needed, as we will never use the exact expression.]}
\begin{equation}
\int_{0}^{1} dx u_{j}(x) \approx\int_{-\infty}^{\infty} u_{j}(x) = A
\sqrt{2\pi\sigma^{2}}, \label{Eq:bulk-approx}%
\end{equation}
where the approximation is valid when $c_{j}$ is far from stimulus boundaries and
$\sigma$ is small with respect to the stimulus range. Since we consider a large
number of neurons in the first layer and relatively small $\sigma$ (up to
$1/10$ of the stimulus range), the effects of this approximation in our
results are negligible. By inserting Eq. (\ref{Eq:bulk-approx}) and a similar
approximation for $\int_{0}^{1} dx u_{j}(x)^{2}$ into Eq.
(\ref{Eq:resource-constraint-ext}), we obtain 
\begin{equation}
A^{2} = \frac{R}{\sqrt{\pi\sigma^{2}} - 2\pi\sigma^{2}}.
\end{equation}
\newline\newline\textbf{Gaussian process interpretation.} The response of each
neuron of the second layer to a fixed stimulus $x$ is a sum of Gaussian random
variables. As a result, it is also a Gaussian random variable with mean
\begin{equation}
\langle v_{i}(x) \rangle_{W} = \sum_{j=1}^{L} \langle W_{ij}\rangle_{W}
u_{j}(x) = 0. \label{Eq:GP-mean}%
\end{equation}
The covariance between the response of the same neuron to two different
stimuli, $x$ and $x^{\prime}$, is given by
\begin{equation}
\left\langle v_{i}(x)v_{i}(x^{\prime}) \right\rangle _{W} = \sum_{j,j^{\prime
}} \left\langle W_{ij}W_{ij^{\prime}} \right\rangle _{W} u_{j}(x)
u_{j^{\prime}}(x^{\prime}) = \sum_{j=1}^{L} \frac{1}{L} u_{j}(x)
u_{j}(x^{\prime}).
\end{equation}
We can approximate the discrete sum with the integral $\sum_{j=1}^{L} f(c_{j})
\Delta c_{j} \approx\int_{0}^{1} f(c_{j}) dc_{j}$ , and the error of this
approximation will be of order $1/L$. Finally, we obtain the covariance function
\begin{equation}
\begin{split}
\left\langle v_{i}(x)v_{i}(x^{\prime}) \right\rangle _{W}  &  \approx\int
_{0}^{1} dc_{j} u_{j}(x)u_{j}(x^{\prime})\\
&  = A^{2} \int_{0}^{1} dc_{j} \exp\left(  -\frac{\left(  \left(
x-c_{j}\right)  ^{2} + \left(  x^{\prime}-c_{j}\right)  ^{2}\right)  }
{2\sigma^{2}}\right) \\
&  \approx A^{2} \sqrt{\pi\sigma^{2}}\exp\left(  -\frac{\Delta x^{2}}
{4\sigma^{2}}\right)  ,\label{Eq:GP-cov}
\end{split}
\end{equation}
where $\Delta x = x -x^{\prime}$. In the last line we took the limit of
integration going to infinity, similarly to Eq. (\ref{Eq:bulk-approx}); this
approximation is valid if the arithmetic mean of  $x$ and $x^{\prime}$ is far from the
stimulus boundaries.
Equation (\ref{Eq:GP-mean}) and Equation (\ref{Eq:GP-cov}) show that each
neuron tuning curve is a sample from a one-dimensional Gaussian process with 0
mean and squared exponential kernel with correlation length equal to $\sqrt
{2}\sigma$ \cite{Rasmussen2004GaussianLearning}. \newline\newline

\subsection*{Encoding - decoding}

\textbf{Noise Model.} Representation neurons are affected by additive
isotropic Gaussian noise. At each trial, the vector of responses to a given
stimulus $x$ is obtained as
\begin{equation}
\mathbf{r} = \mathbf{v}(x) + \mathbf{z }, \label{Eq:r}%
\end{equation}
where $\mathbf{z}$ is a noise vector of independent Gaussian entries with a
fixed variance, $z_{i} \sim\mathcal{N}(0,\eta^{2})$. Here, $\mathbf{v}(x) =
\{v_{1}(x),v_{2}(x),...,v_{N}(x)\}$ is the vector containing the mean
responses of second layer neurons to the same stimulus $x$, Eq.
(\ref{Eq:tuning-curve-layer2}). As a result, we can write the likelihood of a
response given a stimulus as
\begin{equation}
p\left(  \mathbf{r}|x\right)  = \frac{1}{\left(  2\pi\eta^{2}\right)  ^{N/2}}
\exp\left(  - \frac{\left\|  \mathbf{r}-\mathbf{v}(x)\right\|  _{2}^{2}}
{2\eta^{2}} \right)  . \label{Eq:L}%
\end{equation}
This expression can be extended to keep into account a generic noise covariance matrix, 
$\bm{\Sigma}$, leading to

\begin{equation}
p\left(  \mathbf{r}|x\right)  = \frac{1}{\left(  2\pi\right)  ^{N/2}
(\text{det}\left(  \bm{\Sigma}\right)  ^{1/2}} \exp\left(  -\left(  \mathbf{r} -
\mathbf{v}(x)\right)  ^{T}\bm{\Sigma}^{-1}\left(  \mathbf{r} - \mathbf{v}
(x)\right)  \right)  . \label{Eq:LIn}
\end{equation}
\newline\newline\textbf{Loss function and decoder.} 
\textbf{[MIRKO: SHould we add the picture of the decoder? S: I have it, we have enough figures but it can be added in Methods figures.]}
We measured the coding performance of the neural population through  the Mean
Squared Error (MSE) in stimulus estimate \cite{Dayan2001TheoreticalSystems}. For a generic
decoder, or estimator, $\hat{x} = f_{dec}(\mathbf{r})$, the MSE is defined as
\begin{equation}
E^{2} = \int dx \int d\mathbf{r} p(\mathbf{r}|x) \left(  \hat{x} -x\right)
^{2}. \label{Eq:MSE}%
\end{equation}
We considered this quantity averaged over network realizations, $\varepsilon
^{2} \equiv\langle E^{2}\rangle_{W}$; we often plot the square root of this
quantity, $\varepsilon\equiv\sqrt{\langle E^{2}\rangle_{W}}$, since it has the
same unit of measurement of the stimulus. For multidimensional stimuli, we average the squared norm, $\left\|
\hat{\mathbf{x}} - \mathbf{x}\right\|  _{2}^{2}$.

The estimator which minimizes the MSE (Minimum-MSE or MMSE) is given by the
average of the posterior distribution. As we assume an uniform prior over
stimuli, $p(x) \sim\mathcal{U}(0,1)$, we can write the estimator as a function
of the likelihood, as
\begin{equation}
\hat{x}_{MMSE} = \int_{0}^{1} dx p(x| \mathbf{r}) x = \frac{\displaystyle\int%
_{0}^{1} dx p(\mathbf{r}|x)x}{\displaystyle\int_{0}^{1} dx p(\mathbf{r}|x)}.
\label{Eq:dec}%
\end{equation}	In order to numerically implement this estimator, we  approximate the integrals with a discrete sum over $M$ values and, by
inserting Eq. (\ref{Eq:L}), we obtain
\begin{equation}%
\begin{split}
\hat{x}_{MMSE}  &  \approx\frac{\sum_{m=1}^{M} x_{m} p\left(  \mathbf{r}
|x_{m}\right) \Delta x_m  }{\sum_{m=1}^{M} p\left(  \mathbf{r} |x_{m}\right) \Delta x_m   } =
\frac{\sum_{m=1}^{M} x_{m} \exp{\left(  -\frac{1}{2\eta^{2}}\left(\sum_{i=1}^{N}
r_{i}^{2} + \sum_{i=1}^{N} v_{i}^{2} (x_{m}) - 2\sum_{i=1}^{N}v_{i}(x_{m})r_{i} \right)\right)  }}{\sum_{m=1}^{M}
\exp{\left(  -\frac{1}{2\eta^{2}}\left( \sum_{i=1}^{N} r_{i}^{2} + \sum_{i=1}^{N}v_{i}^{2}(x_{m})
- 2\sum_{i=1}^{N}v_{i}(x_{m})r_{i}\right) \right)  }}\\
&  = \frac{\sum_{m=1}^{M} x_{m} \exp{\left(  \frac{1}{2\eta^{2}}\left(\sum_{i=1}^{N}
2v_{i}(x_{m})r_{i} -\sum_{i=1}^{N}v_{i}^{2}(x_{m})\right)\right)  }}{\sum_{m=1}^{M} \exp{\left(
\frac{1}{2\eta^{2}} \left(\sum_{i=1}^{N} 2v_{i}(x_{m})r_{i}-\sum_{i=1}^{N}v_{i}^{2}(x_{m})\right)\right)
}} = \sum_{m=1}^M x_m \tilde h_m,
\end{split}
\end{equation}
where in the last step the terms $\sum_{i} r_{i}^{2} $  cancels as it is
common to both numerator and denominator and we assumed a constant $\Delta x_m$. 

This series of operations can be implemented in a two-layer neural network. A first layer of  $M$ neurons, whose activity is given by 
\begin{equation}\tilde h_m = \frac{\exp{\left(  \sum_{i=1}^{N}
\lambda_{mi}r_{i} + b_{m}\right)  }}{\sum_{m'=1}^M \exp{\left(  \sum_{i=1}^{N}
\lambda_{m'i}r_{i} + b_{m'}\right)  }}, 
\end{equation}
computes a normalized discrete approximation of the likelihood, $ \tilde h_m \propto p(\mathbf{r}|x_m)$, such that $\sum_{m=1}^M \tilde h_m =1$. 
The unnormalized activity of neuron $m$, $h_m =\exp{\left(  \sum_{i=1}^{N}
\lambda_{mi}r_{i} + b_{m}\right)} $, is a linear combination
of the activity of the representation neurons plus a bias term, passed
through an exponential non-linearity. The synaptic weights between the $m$-th
decoder neuron and the $i$-th representation neuron, are a function of the
true mean response of neuron $i$ to stimulus $x_{m}$ and the variance of the
noise, $\lambda_{mi} = v_{i}(x_{m})/\eta^{2}$ . Similarly, the bias term is
obtained as $b_{m} = -\sum_{i} v_{i}(x_{m})^{2}/2\eta^{2}$ .   
Finally, to obtain the MMSE estimate, a single neuron weights the activity of these $M$ neurons according to their  `preferred stimulus', $x_{m}$.

In the following discussion, we will often use the Maximum a Posterior (MAP)
estimator, which in this case corresponds to a Maximum Likelihood (ML) estimator, defined as
\begin{equation}
\hat{x}_{MAP} = \argmax_{x_{m}} \tilde h_{m} = \argmin_{x_{m}} \left\|  \mathbf{r} -
\mathbf{v} (x_{m})\right\|  _{2}^{2}, \label{Eq:ML}%
\end{equation}
since it has a simpler geometrical interpretation: it finds the stimulus which
corresponds to the closest vector of mean responses to the noisy output. In
numerical simulations, the MSE for these two estimators are very similar.

The same decoder can be extended to deal with the case of non-diagonal noise
covariance matrix $\sigma$, plugging Eq. (\ref{Eq:LIn}) into Eq.
(\ref{Eq:dec}) . The decoding weights and biases are now correlated,
$\mathbf{\lambda}_{m} = \mathbf{v}^{T}(x_{m} )\sigma^{-1}$ and $b_{m} =
\mathbf{v}^{T}(x_{m})\sigma^{-1}\mathbf{v}(x_{m})$, where $\lambda_{m}$
denotes the $m$-th row of $\lambda$.

In numerical simulations, we computed the MSE with standard Monte Carlo
method. We generated the noisy responses to sampled stimuli and we decoded
them using the ideal decoder, updating the estimated MSE until convergence (i.e., until the estimate was within a tolerance of $10^{-8}$ in the last $500$ steps, after a burn-in period of 4000 steps). For the sake of simplicity and to avoid any limitations to the decoder, we
set the number of decoder neurons equal to the number of sensory neurons,
$M=L$, with uniformly space preferred stimuli, $x_{m} = m/M$.
%This quantity is generally hard to compute. In numerical
%simulations we computed this integral with standard Monte Carlo method. We sampled stimuli uniformly from the stimulus space, we generated a noisy response and we decoded and we updated the value of the MSE,
%iterating this process until when the MSE estimate was within a tolerance of
%$10^{-7}$ in the last 100 steps, after 5000 steps of relaxation.
\newline

\subsection*{Errors computation}

\textbf{Narrow tuning curves.} If $\sigma\rightarrow0$, the first layer
neurons respond only to their preferred stimulus. For this limit case, we
consider that the stimulus can take only $L$ discrete values, $x_{j} = j/L$.
The responses of the second layer neurons are given by $v_{i}(x_{j}) =
\tilde{A}W_{ij}$, with $\tilde{A}^{2} = L R$ such to have $v_{i}(x_{j})
\sim\mathcal{N}(0,R)$ . The constant of proportionality is computed with the analog of Eq. (\ref{Eq:resource-limitation}) for discrete stimuli, in the limit of large $L$.

We denote with $p_{e}(\mathbf{r}|x_{j}) = p(\mathbf{r}|x_{j})\Theta\left(
|\hat{x}-x_{j}|\right)  $ the probability density function that the noise will
produce an error in decoding the response associated to stimulus $x_{j}$. With
a small abuse of notation, we define the Heaviside function as $\Theta(z) = 1$
if $z>0$, and 0 otherwise. When we take the average over synaptic weights, the
probability of having an error on a stimulus $x_{j}$ is independent on the
decoded stimulus $\hat{x}$. The average MSE, Eq. (\ref{Eq:MSE}), can be
therefore approximated as \textbf{[MIRKO (AND SIMONE): This passage is not easy to justify, although the final formula is easy to understand. My reasoning is: the probability of having an error on a given stimulus, and the relative error, are dependent, and linked by the synaptic matrix W. We make the approximation that the probability of having an error on a stimulus and the MSE are two independent r.v., given the realization of W. As a result, in computing the average of the product, we can simply compute the product of the average.]}

\begin{equation}%
\begin{split}
\langle E^{2} \rangle_{W}  &  = \ \frac{1}{L}\sum_{j=1}^{L}\left\langle \int
d\mathbf{r} p_{e}(\mathbf{r}|x_{j}) \left(  \hat{x}-x_{j} \right)
^{2}\right\rangle _{W}\\
&  \approx\left\langle P(E)\right\rangle _{W} \left\langle \frac{1}{L}%
\sum_{j=1}^{L} (\hat{x}-x_{j})^{2}\right\rangle _{W},\label{Eq:PE}%
\end{split}
\end{equation}
where $\left\langle P(E)\right\rangle _{W} = \left\langle \int d\mathbf{r}
p_{e}(\mathbf{r}|x_{j})\right\rangle _{W}$ is the average probability that,
given a stimulus, the noise will cause an error in its estimate. Despite the
notation, it does not depend on the specific value of $x_{j}$. This formula
has an intuitive interpretation: the MSE is the mean probability of having an
error on a stimulus multiplied by the average squared error. By noticing that,
if there is an error, the decoder can output any of the others $L-1$ stimuli,
we obtain

\begin{equation}
\left\langle \frac{1}{L}\sum_{j=1}^{L} (\hat{x}-x_{j})^{2}\right\rangle _{W}
=\frac{1}{L^{2}}\sum_{j=1}^{L} \sum_{j^{\prime}=1,j^{\prime}\neq j}^{L}
\left(  \frac{j^{\prime}} {L}-\frac{j}{L}\right)  ^{2} \approx\frac{1}{6},
\end{equation}
where the last approximation holds for large $L$. The thing to notice here is
that this quantity is of order $1$, the size of the stimulus range. The
average probability of error is the probability that it exists one $j^{\prime
}$ such that $\mathbf{r}$ is closer to $\mathbf{v}(x_{j^{\prime}})$ than to
$\mathbf{v}(x_{j})$. We can express this probability as a function of the
probability of the complementary event,
\begin{equation}
\left\langle P(E)\right\rangle _{W} = 1 - \left\langle P\left(  \left\|
\mathbf{r}-\mathbf{v}(x_{j^{\prime}})\right\|  _{2}^{2} >\left\|  \mathbf{r}
-\mathbf{v}(x_{j})\right\|  _{2}^{2} \quad\forall j \neq j^{\prime}\right)
\right\rangle _{W}.
\end{equation}
Averaging over different realizations of the synaptic matrix, the probability
of not having an error on $x^{\prime}$are i.i.d for different $j^{\prime}$,
and we can write
\begin{equation}
\begin{split}
\langle P(E)\rangle_{W}  &  = 1 - \left(  1 - \left\langle P\left(  \left\|
\mathbf{r}-\mathbf{v}(x_{j^{\prime}})\right\|  _{2}^{2} < \left\|  \mathbf{r}
-\mathbf{v}(x_{j})\right\|  _{2}^{2} \right)  \right\rangle _{W}\right)
^{L-1}\\
&  \approx L \left\langle P\left(  \left\|  \mathbf{r}-\mathbf{v}%
(x_{j^{\prime}})\right\|  _{2}^{2} < \left\|  \mathbf{r} -\mathbf{v}%
(x_{j})\right\|  _{2}^{2} \right)  \right\rangle _{W}\\
&  = L \left\langle P\left(  \sum_{i=1}^{N} \left(  v_{i} (x_j)- v_{i}%
(x_{j^{\prime}})\right)  ^{2} - \sum_{i=1}^{N}2\left(  v_{i}(x_j)-v_{i}(x_{j^{\prime}
})\right)  z_{i} < 0 \right)  \right\rangle _{W}.
\end{split}
\end{equation}
In the first step, we assumed that the
probability of having an error on a stimulus $x_{j}$ is small, and $L-1
\approx L$ is large, such that we can approximate $(1-z)^{L} \approx1 -Lz$. In
the last step we simply inserted Eq. (\ref{Eq:r}). The difference between
the response of the same neuron to two different stimuli, averaged over
different synaptic weights realizations, has a Gaussian distribution,
$\tilde{v_{i}} \equiv v_{i}(x_{j})-v_{i}(x_{j^{\prime}}) = \tilde{A}(W_{ij}
-W_{ij^{\prime}}) \sim\mathcal{N}(0,2R)$. By averaging over the noise
distribution too, the probability of error reads

\begin{equation}
\left\langle P(E)\right\rangle _{W} \approx L \int\prod_{i=1}^{N} d \tilde
{v}_{i} \prod_{i=1}^{N} dz_{i} p(\tilde{v}_{i}) p(z_{i}) \Theta\left(
-\sum_{i=1}^{N} \tilde{v}^{2}_{i} +2\sum_{i=1}^{N} \tilde{v}_{i} z_{i}\right)
.
\end{equation}
This is the probability that the random variable $\rho= \sum_{i=1}^N \tilde{v}_{i}^{2} -
\sum_{i=1}^{N}2\tilde{v}_{i} z_{i}$ is less than 0, where $\tilde{v}_{i} \sim\mathcal{N}%
(0,2R)$ and $z_{i} \sim\mathcal{N}(0,\eta^{2})$. We can compute this quantity
by noticing that, if we fix $\zeta= \sum_{i=}^N \tilde{v}^{2}_{i}$, the
conditional distribution of $\rho$ is Gaussian, $\rho|\{\tilde{v}_{i}^{2}\}
\sim\mathcal{N}(\zeta,4\zeta\eta^{2}) $. By using the definition of error
function we can rewrite the error probability as
\begin{equation}%
\begin{split}
\langle P(E)\rangle_{W}  &  \approx L\int_{0}^{\infty}d\zeta p(\zeta)
\int_{-\infty}^{0} d\rho p(\rho|\zeta)\\
&  = \frac{L}{2}\int_{0}^{\infty}d\zeta p(\zeta)
\erfc{\left(\sqrt{\frac{\zeta}{8\eta^2}}\right)},
\end{split}
\end{equation}
where $p(\zeta) = \frac{(\zeta/2R)^{N/2 -1}\exp\left(  - \zeta/4R\right)
}{2^{N/2 +1} \Gamma(N/2)}$ is the probability density function of a
Chi-squared distribution. Computing this integral, we obtain
\begin{equation}%
\begin{split}
\left\langle P(E)\right\rangle _{W}  &  \approx L \frac{(\frac{\eta^{2}}
{2R})^{\frac{N}{2}}\Gamma(N)}{\Gamma(\frac{N}{2})} {}_{2}\tilde{F}_{1}\left(
\frac{N}{2},\frac{1+N}{2},\frac{2+N}{2},-2\frac{\eta^{2}}{R} \right) \\
&  =L \frac{\left(  \frac{\eta^{2}}{2R}\right)  ^{\frac{N}{2}}\Gamma\left(
N\right)  }{\Gamma\left(  \frac{N} {2}\right)  \Gamma\left(  \frac{2+N}%
{2}\right)  }\sum_{n=0}^{\infty}\frac{\left(  \frac{N}{2}\right)  _{n} \left(
\frac{N+1}{2}\right)  _{n}}{\left(  \frac{N+2}{2}\right)  _{n} n!} \left(
-2\frac{\eta^{2}}{R}\right)  ^{n},
\end{split}
\end{equation}
where ${}_{2}\tilde{F}_{1}(a,b,c,x)$ is the regularized 2F1 Hypergeometric
function and in the second line we substituted its definition. The Pochammer
symbol is also defined through Gamma functions, $(x)_{n} = \frac{\Gamma
(x+n)}{\Gamma(x)}$. Simplifying and using the identity $\sum_{n=0}^{\infty
}\frac{(x)_{n}}{n!} a^{n} = (1-a)^{-x}$, we obtain the expression for the
error probability which appears in the main text
\begin{equation}%
\begin{split}
\langle P(E)\rangle_{W}  &  \approx L (\frac{\eta^{2}}{2R})^{\frac{N}{2}}
\frac{\Gamma(N)}{\Gamma^{2}(\frac{N}{2}) \frac{N}{2} (1+2\eta^{2}%
/R)^{\frac{N+1}{2}}}\\
&  \approx\frac{L}{\sqrt{2\pi N}} \exp{\left(  - \log\left(  1 + \frac
{R}{2\eta^{2}}\right)  \frac{N}{2}\right)  },
\end{split}
\tag{\ref{Eq:PGE} restated}%
\end{equation}
where in the last step we used the Stirling approximation for the Gamma
functions. 
\newline\newline
\textbf{Broad tuning curves.} In this case we consider continuous stimuli, and the noise can also produce small scale errors; we therefore consider two contributions to the error:
local and global. Since our system has a natural correlation length, Eq.
(\ref{Eq:GP-cov}), we define as global an error when the difference between
the stimulus and its estimate is greater than $\sigma$, $|\hat{x} - x |>
\sigma$. 
Despite this definition may seem bit tricky, as for very large $\sigma$ all the
errors will be local, the maximum value we considered for $\sigma$ is still quite small, about $1/10$ of the stimulus range. 
We rewrite the MSE as
\begin{equation}
\varepsilon^{2} = \left\langle E^{2} \right\rangle _{W}= \left\langle
E_{l}^{2} + E_{g}^{2} \right\rangle _{W}= \left\langle \int dx d\mathbf{r}
p_{l} \left(  \mathbf{r}|x\right)  \left(  \hat{x} -x \right)  ^{2}%
\right\rangle _{W} + \left\langle \int dx d\mathbf{r}p_{g}(\mathbf{r}|x)
\left(  \hat{x} -x \right)  ^{2} \right\rangle _{W},
\end{equation}
where $p_{l/g}(\mathbf{r}|x) = p(\mathbf{r}|x) \Theta\big(\pm(\sigma- |\hat
{x}-x|)\big)$ denotes the probability density function that, given $x$, the
noise will cause a local/global error. It holds the following normalization
$\int d\mathbf{r} \left(p_{l}(\mathbf{r}|x) + p_{g} (\mathbf{r}|x)\right)=1$.
\newline\newline\textbf{Local error.} According to the ML decoder, Eq.
(\ref{Eq:ML}), the stimulus estimate will correspond to the $x^{\prime}$ such
that $\mathbf{v}(x^{\prime})$ has the minimal distance from $\mathbf{r}$. If
the error is local, this point corresponds to the projection of the noise
vector onto the response curve. By expanding linearly the response curve
around $\mathbf{v}(x)$, we obtain
\begin{equation}
\left\|  \mathbf{z}\cdot\hat{\mathbf{v^{\prime}}}(x)\right\|  _{2}^{2}
\approx\left\|  \mathbf{v}(x+\Delta x)-\mathbf{v}(x)\right\|  _{2}^{2}
\approx\left\|  \mathbf{v^{\prime}}(x)\right\|  _{2}^{2}\Delta x^{2},
\label{Eq:lin-exp}%
\end{equation}
where $\mathbf{v^{\prime}}(x) = \partial\mathbf{v}(x)/\partial x$ and
$\hat{\mathbf{v^{\prime}}}(x)$ is the normalized vector with the same
direction. The error can be estimated as $\Delta x^{2} = \left(  \hat
{x}-x\right)  ^{2} = \frac{\left\|  \mathbf{z}\cdot\hat{\mathbf{v^{\prime}}%
}(x)\right\|  _{2}^{2}}{\left\|  \mathbf{v^{\prime} }(x)\right\|  _{2}^{2}}$ .
We will show that the probability of global error will be exponentially small
in $N$, therefore we can approximate $p_{l} (\mathbf{r}|x)$ with the whole
Gaussian, Eq. (\ref{Eq:L}). When integrating over the isotropic Gaussian
noise, the magnitude of the projection onto a fixed unit vector will be simply
equal to the the variance. We obtain therefore
\begin{equation}
\begin{split}
\left\langle E_{l}^{2}\right\rangle _{W}  &  = \left\langle \int_0^1 dx \int
d\mathbf{z} \frac{ \left\|  \mathbf{z}\cdot\hat{\mathbf{v^{\prime}}
}(x)\right\|  _{2}^{2} }{\left\|  \mathbf{v^{\prime}}(x)\right\|  _{2}^{2}
}\right\rangle _{W}\\
&  =\left\langle \int_0^1 dx \frac{\eta^{2} }{\left\|  \mathbf{v^{\prime}
}(x)\right\|  _{2}^{2}}\right\rangle _{W}
\end{split}
\end{equation}
We now approximate the average of the inverse with the inverse of the average
of the derivative of the tuning curves, $\left\langle 1 / \cdot\right\rangle
_{W} \approx1/ \left\langle \cdot\right\rangle $, an approximation which is
valid if $L$ is large and $\sigma$ is small with respect to stimulus range.
For the average derivative of the tuning curves, we obtain
\begin{equation}
\begin{split}
\left\langle \left\|  \mathbf{v^{\prime}}(x)\right\|  _{2}^{2}\right\rangle
_{W}  &  = \left\langle \sum_{i=1}^N \left(  \sum_{j=1}^{L} W_{ij} \frac{\partial u_{j}%
(x)}{\partial x}\right)  ^{2} \right\rangle _{W} = \left\langle \sum_{i=1}^N\left(
\sum_{j=1}^{L} W_{ij} \frac{\left(  x-c_{j}\right)  }{\sigma^{2}}u_{j}(x)
\right)  ^{2}\right\rangle _{W}\\
&  = \sum_{i=1}^{N} \sum_{jj^{\prime}} \left\langle W_{ij}W_{ij^{\prime}%
}\right\rangle _{W} \frac{(x-c_{j})(x-c_{j^{\prime}} )}{\sigma^{4}} u_{j}(x)
u_{j^{\prime}}(x)\\
&  = \frac{N }{\sigma^{4}} \sum_{j=1}^{L}\frac{1}{L} \left(  x-c_{j}\right)
^{2} u_{j}^{2}(x) \approx\frac{N }{\sigma^{4}} \int_{0}^{1} dc_{j} \left(
x-c_{j}\right)  ^{2} u_{j}^{2}(x)\\
&  \approx\frac{NA^{2} \sqrt{\pi\sigma^{2}}}{2\sigma^{2}},
\end{split}
\label{Eq:tcd}%
\end{equation}
where in the last step we approximated the sum with the integral and we took
the limit of integration going to infinity, similarly to previous
calculations. Finally, by using the approximation for small $\sigma$, $A^{2}
\approx R/\sqrt{\pi\sigma^{2}}$, we get the expression which appears in the main text

\begin{equation}
\varepsilon_{l}^{2} = \langle E _{l}^{2}\rangle_{W} \approx\frac{2\sigma
^{2}\eta^{2}}{R N}.
\end{equation}
This expression is equivalent to the inverse of the average Fisher
Information, which, in case of neurons affected by i.i.d Gaussian noise, is
given by $J(x) = \left\|  \mathbf{v^{\prime}}(x)\right\|  _{2}^{2}/\eta^{2}$.
\newline\newline\textbf{Global error.} In computing an approximation for the
scaling of global errors, we extend the reasoning we have done for discrete
stimuli. By assuming that the magnitude of a global error is independent on
its probability, we write an expression similar to Eq. (\ref{Eq:PE}),
\begin{equation}
\left\langle E^{2}_{g}\right\rangle _{W} = \left\langle P(E)\right\rangle _{W}
\left\langle \int_{0}^{1} dx (\hat{x}-x)^{2}\right\rangle _{W}.
\end{equation}
We use the approximation that, in case of global error, the decoded
stimulus, averaging over different distributions of synaptic weights, is
uniformly distributed in the interval $\hat{x} \not \in [x-\sigma,x+\sigma]$.
The average magnitude of global errors is therefore
\begin{equation}
\begin{split}
\bar{\varepsilon}_{g} &= \left\langle \int_0^1 dx \left(  \hat{x}-x\right)
^{2}\right\rangle _{W} \approx \int_0^1 dx \frac{1}{\left(1-2\sigma\right)}\left[\int_{0}^{x-\sigma} d\hat{x} (\hat{x} -x)^2 + \int_{x+\sigma}^1d\hat{x} (\hat{x}-x)^2\right]\\
&= \frac{1}{6}\frac{\left(1-4\sigma^3\right)}{\left(1-2\sigma\right)} \approx \frac{1}{6} ,
\end{split}
\end{equation}
where, for simplicity, we considered only the case where $x-\sigma >0 $ and $x+\sigma<1$. The important thing to notice here is that it is a term of order $1$, the size of the stimulus range.

The probability of an error being global,
averaged over different realizations of $W$, does not depend on the specific
value of the stimulus. Computing this probability rigorously is hard, due to
the correlations between nearby responses. Nevertheless, we know that for
stimuli at a distance greater than $\sigma$ the two responses are basically
uncorrelated, Eq. (\ref{Eq:GP-cov}). We divide the curve into
$1/\sigma$ uncorrelated segments of responses, and we consider the distance between these segments sampled randomly; therefore, it is sufficient to substitute to 
$L$ in Eq. (\ref{Eq:PGE}) the number of segments, to obtain the expression of the global error which appears in the main text,
\begin{equation}
\varepsilon_{g}^{2} = \left\langle E_{g}^{2}\right\rangle _{W} \approx\frac{1
}{\sigma\sqrt{2\pi N}}\bar{\varepsilon}_{g} \exp{\left(  -\log\left(  1 +
\frac{R} {2\eta^{2}}\right)  \frac{N}{2} \right)  }.
\end{equation}
\newline\newline\textbf{Input noise.} We consider the case in which the first
layer responses are affected by i.i.d Gaussian noise, $\mathbf{\tilde u}(x) =
\mathbf{u}(x) + \mathbf{z^{u}} $, with $z^{u}_{i} \sim\mathcal{N}(0,\xi^{2})$.
This results in a multivariate Gaussian distribution for the responses of the
second layer, Eq. (\ref{Eq:LIn}), with covariance matrix $\bm{\Sigma}= \eta^{2}
\mathbf{I} + \xi^{2} \mathbf{W} \mathbf{W}^{T}.$ The matrix $\mathbf{W}\mathbf{W}^{T}$ follows the well known Wishart distribution,
with mean $\mathbf{I}$ and fluctuations of order $1/L$. We rewrite the
covariance matrix as the sum of the identity plus a perturbation
\begin{equation}
\bm{\Sigma}= \tilde\eta^{2} \mathbf{I} + \xi^{2}(\mathbf{WW^T -I}),
\end{equation}
where $\tilde\eta^{2} = \eta^{2} + \xi^{2} $. In order to obtain an estimate
of the effects of input noise on the local error, we consider the inverse of
the Fisher Information (FI) as a lower bound to the MSE. For correlated
populations, the FI is given by \cite{Shamir2006ImplicationsCoding}
\begin{equation}
J(x) = \mathbf{v^{\prime}}(x)^{T} \bm{\Sigma}^{-1}\mathbf{v^{\prime}}(x).
\end{equation}
If the perturbation matrix is small, we can approximate the inverse of the
correlation matrix at the second order \newline$\bm{\Sigma}^{-1} \approx\frac
{1}{\tilde\eta^{2}} \mathbf{I} - \frac{\xi^{2}}{\tilde\eta^{4}} \left(
\mathbf{WW^T}-\mathbf{I}\right)  + \frac{\xi^{4}} {\tilde\eta^{6}}\left(
\mathbf{WW^T}-\mathbf{I}\right)  ^{2} $, and write the FI as

\begin{equation}%
\begin{split}
J(x)  &  \approx J^{ind}(x) - \delta J(x)\\
&  = \frac{\left\|  \mathbf{v^{\prime}}(x)\right\|  _{2}^{2}}{\tilde\eta^{2}}
-\frac{\xi^{2}} {\tilde\eta^{4}} \mathbf{u^{\prime}}^{T}(x) \left(
\mathbf{B}^{2} - \mathbf{B} \right)  \mathbf{u^{\prime}}(x) + \frac{\xi^{4}%
}{\tilde\eta^{6}}\mathbf{u^{\prime} }^{T}(x) \left(  \mathbf{B}^{3} -
2\mathbf{B}^{2} + \mathbf{B}\right)  \mathbf{u^{\prime} }(x),
\end{split}
\label{Eq:FIapprox}%
\end{equation}where $\mathbf{B}= \mathbf{W^T W }$.
We recognize in the first term, $J^{ind}(x)$, the FI in the case of i.i.d
Gaussian output noise with variance $\tilde{\eta}^{2}$. All the correction
terms to the FI are related to the moments of the matrix $\mathbf{B}$. Since
all the entries are Gaussian, it is possible to compute their mean through the
Isserlis' theorem. Using the identity $\left\langle W_{ij}W_{mn}\right\rangle
_{W} = \frac{1}{L}\delta_{im} \delta_{jn}$, we obtain:
\begin{equation}
\left\langle B_{mn}\right\rangle _{W} = \left\langle \sum_{j=1}^{N} W_{jm}
W_{jn}\right\rangle _{W} = \frac{N}{L}\delta_{mn},
\end{equation}
\begin{equation}
\left\langle B^{2}_{mn}\right\rangle _{W} = \left\langle \sum_{i=1}^{L}
\sum_{j=1,j^{\prime}=1}^{N} W_{jm} W_{ji}W_{j^{\prime}i}W_{j^{\prime}
n}\right\rangle _{W} = \left\langle \frac{N}{L} + \frac{N^{2}}{L^{2}} +
\frac{N}{L^{2}}\right \rangle \delta_{mn},
\end{equation}
\begin{equation}
\left\langle B^{3}_{mn}\right\rangle _{W} = \left\langle \sum_{i=1,i^{\prime}
=1}^{L} \sum_{j=1,j^{\prime}=1,j^{\prime\prime}=1}^{N} W_{jm}W_{ji}
W_{j^{\prime}i}W_{j^{\prime}i^{\prime}}W_{j^{\prime\prime}i^{\prime}%
}W_{j^{\prime\prime}n}\right\rangle _{W} =\left(  \frac{N^{3} }{L^{3}} +
3\frac{N^{2}}{L^{3}} + 3\frac{N^{2}}{L^{2}} + 4\frac{N}{L^{3}} + 3\frac
{N}{L^{2}} + \frac{N}{L} \right)  \delta_{mn}.
\end{equation}
To leading order in $N/L$, the mean of
the perturbation term read
\begin{equation}%
\begin{split}
\left\langle \delta J(x)\right\rangle _{W}  &  \approx\frac{N^{2}\xi^{2}
}{L^{2}\tilde\eta^{4}} \mathbf{u^{\prime}}(x)^{T} \mathbf{I} \mathbf{u^{\prime
}}(x) -\frac{N^{2}\xi^{4}}{L^{2}\tilde\eta^{6}} \mathbf{u^{\prime}}(x)^{T}
\mathbf{I} \mathbf{u^{\prime}}(x)\\
&  = \frac{N^{2}\xi^{2}A^{2} \sqrt{\pi\sigma^{2}}}{2L\tilde\eta^{4} \sigma
^{2}}\left(  1- \frac{\xi^{2}}{\tilde\eta^{2}}\right)  ,
\end{split}
\label{Eq:deltaJ}%
\end{equation}
where we computed $\mathbf{u^{\prime}}(x)^{T} \mathbf{I} \mathbf{u^{\prime}%
}(x) = \sum_{j=1}^{L} u^{\prime}_{j}(x)^{2} $ in the same way of Eq.
(\ref{Eq:tcd}). By inserting Eq. (\ref{Eq:tcd}) and Eq. (\ref{Eq:deltaJ}) in
Eq. (\ref{Eq:FIapprox}), we obtain the expression for the FI in case of input
noise
\begin{equation}
\left\langle J(x)\right\rangle _{W} \approx\frac{ A^{2} N \sqrt{\pi\sigma^{2}%
}}{2 \sigma^{2}\tilde\eta^{2}}\left(  1 -\frac{N\xi^{2}}{L\tilde\eta^{2}}+
\frac{N\xi^{4}}{L\tilde\eta^{4}}\right)  ,
\end{equation}
and the approximation for the MSE which appears in the main
text,
\begin{equation}
\varepsilon_{l}^{2} = \langle E^{2}\rangle_{W} \approx\frac{1}{\langle
J(x)\rangle_{W}} \approx\varepsilon_{l,\text{ind}}^{2} \left(  1+\frac
{N\xi^{2}}{L\tilde\eta^{2}} - \frac{N\xi^{4}}{L\tilde\eta^{4}}\right)  ,
\tag{\ref{Eq:IN} restated}%
\end{equation}
where $\varepsilon_{l,\text{ind}}^{2} \approx2\sigma^{2}\tilde\eta^{2}/R N. $
Similar calculations can be done assuming a covariance matrix with the same
statistic, but uncorrelated with the synaptic weights. As an example, we
considered $\bm{\Sigma_{rand}} = \eta^{2} I + \xi^{2} \mathbf{X}\mathbf{X}^{T}$
with $X_{ij} \sim\mathcal{N}(0,\frac{1}{L})$ such that $\left\langle
X_{ij}W_{mn}\right\rangle _{W,X}= 0$. In this case we have no first order
corrections, and the FI is increased
\begin{equation}
\langle J(x)\rangle_{W,X} \approx\frac{A^{2} N \sqrt{\pi\sigma^{2}}}{2
\sigma^{2}\tilde\eta^{2}}\left(  1 + \frac{N\xi^{4}}{L\tilde\eta^{4}}\right)
,
\end{equation}
yielding a lower MSE, Eq. (\ref{Eq:Rand}).

\subsection*{Extension to multidimensional stimuli}

We consider stimuli in the hypercube $\mathbf{x} \in[0,1]^{K}$and the two
extreme cases of pure and conjunctive sensory neurons. \newline\newline
\textbf{Pure case.} Each sensory neuron is sensitive to a single stimulus
dimension, $x_{k}$. The $L$ neurons are equally assigned to stimulus
dimensions, such that each dimension is monitored by $Q = L/K$ neurons. The
activity of neuron $u_{j,k}$ is given by
\begin{equation}
u^{p}_{j,k}(\mathbf{x}) = u^{p}_{j,k}(x_k) = A_{p} \exp\left(  -\frac{\left(  x_{k} - c^k_j
\right)  ^{2}}{2\sigma^{2}}\right)  ,
\end{equation}
with preferred stimuli evenly spaced, $c^k_{j} = j/Q \text{ for }
j=1,...,Q $. The responses of second layer neurons are given by a random
sum of all sensory neurons, and can be written as a superposition of
one-dimensional tuning curves, independent for each dimension,
\begin{equation}
\begin{split}
v_{i}^{p}(\mathbf{x})  &  = \sum_{k=1}^{K} \sum_{j=1}^{Q} W_{ijk}
u_{j,k}(\mathbf{x})\\
&  = \sum_{k=1}^{K} v_{i,k}^{p}(x_{k}).
\end{split}
\end{equation}
Imposing the resource constraint, Eq. (\ref{Eq:resource-constraint-ext}), with
similar calculations we obtain $A_{p}^{2} = R/\left(  \left(  \pi\sigma
^{2}\right)  ^{1/2} - 2\pi\sigma^{2}\right)  $.

The local error along each dimension is computed, similarly to Eq.
(\ref{Eq:lin-exp}), expanding linearly the surface, and obtaining
\begin{equation}
\Delta x_{k}^{2} \approx\frac{\left\|  \mathbf{z}\cdot\hat{\mathbf{v^{\prime}%
}}_{k}(\mathbf{x})\right\|  _{2}^{2}}{\left\|  \mathbf{v^{\prime}}_{k}(\mathbf{x})\right\|
_{2}^{2}}, \label{Eq:MD-le}%
\end{equation}
where $\mathbf{v^{\prime}}_{k} = \partial\mathbf{v}(\mathbf{x})/\partial x_{k}$. The
calculation is analogous to the one-dimensional case, but the derivative along
each dimension acts only on $1/K$ terms. As a consequence, the local error
along each dimension is
\begin{equation}
\varepsilon^{2}_{l,p,k} = \frac{2 K \sigma^{2} \eta^{2}}{N A_{p}^{2} \sqrt
{\pi\sigma^{2}}} \approx\frac{2 K \sigma^{2} \eta^{2}}{RN},
\label{Eq:multi-local-pure}%
\end{equation}
and the total one is $\varepsilon^{2}_{l,p} = K\varepsilon_{l,p,k}^{2}$.

As for global errors, since the multi-dimensional tuning curves are
superposition of one-dimensional ones, we can obtain a global error on each
dimension independently. By assuming that the probability of having a global
error on more than one dimension is negligible, we can approximate the total
probability of having a global error as the sum of probabilities along each
dimension, $P(E_{g}) = \sum_{k=1}^{K} P(E_{g,k})$. In computing the
probability along each dimension, we have to keep into account that, as the
total variance across all stimulus space is equal to $R$, the variance across
each dimension is reduced by a factor of $K$. By inserting $R/K$ instead of
$R$ in Eq. (\ref{Eq:PGE}) and summing over the dimensions, we obtain that the
global error for the pure case scales approximately as
\begin{equation}
\varepsilon_{g,p}^{2} \approx\frac{K\bar{\varepsilon}_{g} }{\sigma\sqrt{2\pi
N}} \exp{\left(  -\log\left(  1 + \frac{R} {2 K \eta^{2}}\right)  \frac{N}{2}
\right)  }, \label{Eq:multi-global-pure}%
\end{equation}
where the average magnitude of global error, $\bar{\varepsilon}_{g}$, is again
a term of order 1. \newline\newline\textbf{Conjunctive case.} In this case the
response of sensory neurons are multi-dimensional Gaussian,
\begin{equation}
u^{c}_{j}\left(  \mathbf{x}\right)  =A_{c} \exp{\left(  -\frac{\left\|
\mathbf{x}-\mathbf{c}_{j}\right\|  _{2}^{2}} {2\sigma^{2}}\right)  },
\end{equation}
with preferred stimuli arranged on a $K$-dimensional square grid of side $L^{-1/K}$. The response of the second layer neurons are given by
\begin{equation}
v^{c}_{i}(\mathbf{x}) = \sum_{j=1}^L W_{ij} u_{j}^c(\mathbf{x}).
\end{equation}
In this case, the tuning curves of the representation layer are multi-dimensional Gaussian processes with
covariance function $\left\langle v_i(\mathbf{x})v_i(\mathbf{x} + \Delta
\mathbf{x}) \right\rangle _{W} = A_{c}^{2} \left(\pi\sigma^2\right)^{K/2} \exp{\left(  -\left\|
\Delta\mathbf{x}\right\|  _{2}^{2}/4\sigma^{2} \right)  }$. By imposing the
resource constraint, we obtain $A_{c}^{2} = R/\left(  \left(  \pi\sigma
^{2}\right)  ^{K/2} - (2\pi\sigma^{2})^{K} \right)  $. We notice that, as $K$
becomes large, the edge effects in the approximations such Eq.
(\ref{Eq:bulk-approx}) become more relevant, and the denominator may become
negative. For high number of dimensions, we may need broader widths to cover
the stimulus space, and the difference between Gaussian integrals $\left(
\int d\mathbf{x} u_{j}(\mathbf{x})\right)  ^{2}$ and $\int d\mathbf{x}
u_{j}^{2}(\mathbf{x})$ change sign for large values of $\sigma$. We didn't
encounter this problem for $K=3$ (results of the main text) and in the range
of values for $\sigma$ we explored.

When we compute the local error, Eq. (\ref{Eq:MD-le}), the derivative acts on
all the terms of the sum, as all sensory neurons are sensitive to stimulus
variations. As a result, we obtain, for the local error along each dimension
in the conjunctive case,
\begin{equation}
\varepsilon_{l,c,k}^{2} = \frac{2 \sigma^{2} \eta^{2}}{ NA_{c}^{2} (\pi
\sigma)^{K/2}} \approx\frac{2\sigma^{2} \eta^{2}}{RN},
\label{Eq:multi-local-conj}%
\end{equation}
Simarly, the total one will be $\varepsilon^{2}_{l,c} = K\varepsilon
_{l,c,k}^{2}$. The ratio between local errors in the two cases is therefore
$\varepsilon_{l,c}^{2} /\varepsilon^{2}_{l,p} = 1/K$.

As for global errors, we extend the
reasoning of the one-dimensional case, dividing the $K$
-dimensional surface of responses into $1/\sigma^{K}$ regions of correlated stimuli. By substituting the number of uncorrelated regions to $L$ in Eq.
(\ref{Eq:PGE}), we obtain that the global errors scales approximately as
\begin{equation}
\varepsilon_{g,c}^{2} \approx\frac{1}{\sigma^{K}\sqrt{2\pi N}}\bar
{\varepsilon}_{g} \exp{\left(  -\log\left(  1 + \frac{R}{2\eta^{2}}\right)
\frac{N}{2} \right)  }. \label{Eq:multi-global-conj}%
\end{equation}


\subsection*{Data analysis and model fitting}

\textbf{Data description and summary statistics} The detailed data description
is reported in \cite{Lalazar2016TuningConnectivity}, and data are publicly
available at https://osf.io/u57df/. They consist of the responses (firing
rates) of $N \sim500$ neurons, recorded during an arm posture `hold' task at
27 different positions, with 2 hand orientations, up and down, arranged on
a virtual cube of size 40x40x40 cm. The response of each neuron for each
position is recorded for several trials ($\sim$ 10 trials per position).
Tuning curves are computed by averaging over trials. In order to measure the
level of irregularity of a single tuning curve in a non parametric form, the
authors introduced a complexity measure : for each neuron, it is defined as the
standard deviation of the discrete derivative between the response at one
target position, $\mathbf{x}$ and its response at the closest target, $\mathbf{x} +D_{min}$
\begin{equation}
c(D_{min})_{i} = std\left(  \frac{\left\|  \mathbf{v}(\mathbf{x}) - \mathbf{v}(\mathbf{x}+\Delta \mathbf{x})\right\|  }
{\sqrt{\left\|  \Delta \mathbf{x}\right\|  ^{2}}} s.t. \left\|  \Delta \mathbf{x}\right\|
_{2}^{2} < D_{min}\right)  ,
\end{equation}
where $\mathbf{v}(\mathbf{x})$ is the mean response at stimulus $\mathbf{x}$. In the
data, the $D_{min}$ is imposed by the experiment and is equal to $35$. This
limitation, inherent to the data themselves, prevent us from capturing high
frequency components due to aliasing phenomena. The author measured also
another summary statistic, the distribution of $R^{2}$ values resulting from
the fit of the tuning curves with a linear model, Eq. (\ref{Eq:CosTun}),
\begin{equation}
R^{2}_{i} = 1-\frac{\sum_{\mathbf{x}}\left(
\mathbf{v}_{l}(\mathbf{x}) - \mathbf{v}(\mathbf{x})\right)  ^{2}}{\sum_{\mathbf{x}}
\mathbf{v}(\mathbf{x})^{2}},
\end{equation}
where $\mathbf{v}_{l}(\mathbf{x})$ is the response predicted by a fitted linear model,
and the sum is over the stimuli used in the experiment. The distribution of
these quantities across different neurons is a measure of the irregularity of
the neural population; if the population were perfectly described
by Eq. ( \ref{Eq:CosTun}), the $R^{2}$ distribution would be a delta
function peaked at 1, while the complexity measure would be biased
towards low values.

\textbf{Model fitting.} We considered the tuning curves as a function of the
position only, ignoring the difference in hand orientation. We analyzed
neurons responding with at least 5 spikes/s at more than two positions. We
shifted and normalized the data such that tuning curves have zero mean and
unit variance across different stimuli. We generated an irregular population
with our model, featured by a sensory layer of conjunctive neurons responding
to a three-dimensional stimulus. We used $L= 100^{3}$ neurons, tiling a 200 by
200 by 200 cube, such that the stimulus space is covered without boundary
effects, with preferred stimuli arranged on a square grid of side 2. For
computational reasons, due to the slowness of multiplying large full matrices, $\mathbf{W}$ is taken as a sparse random matrix (sparsity
equal to 0.1) with Gaussian entries, similarly to the model of \cite{Lalazar2016TuningConnectivity}. \textbf{[MIRKO: Add discussion about sparsity here? (SIMONE: I performed some simulations with sparse matrices. Sparsity does not affect our results, as long as the representation neurons receive enough inputs from the first layer, therefore as long as sparsity > $\sigma$. Should we mention it?)]}The tuning curves in the second layer
were normalized one by one to have variance equal to $1$. With respect to the
model of \cite{Lalazar2016TuningConnectivity}, there are two main differences:
in their case the random weights were distributed according to a uniform
distribution, and the random sum was passed through a threshold-linear
function. With this formulation, the model had two tunable parameters: the
tuning width of first layer neurons, $\sigma$, and the the threshold of the
non linear function of the second layer. The only tunable parameter of our
model is $\sigma$.

In order to fit the model, we generated the neural responses of a number of
representation neurons equal to the number of recorded neurons at the same
stimuli (27) of the data. We then computed the distribution of the complexity
measure for different values of $\sigma$ and we chose $\sigma_{f}$ such as to
minimize the Kolmogorov-Smirnov (KS) distance between the distribution of the
model and the one of the data (Fig. \ref{Fig:M1}A).  This is a measure of distance between two probability distributions, and it is obtained as the superior of the difference between the two empirical cumulative distribution functions, $F_{model}(c)$ and $F_{data}(c)$,
\begin{equation}
KS (\sigma) = \sup_c |F_{model}(c) - F_{data}(c)|.
\end{equation}
At the minimum value $\sigma_{f}$, the
two distributions are very similar, even if real data show a broader
distribution of values in both directions; for comparison, the distribution
implied by a linear model is biased towards lower values (Fig. \ref{Fig:M1}B).
For the sake of completeness, we computed the KS distance between the model
and the data also for the $R^{2}$ measure (Fig. \ref{Fig:M1}A, red line). This
quantity simply decreases with $\sigma$, and the model at $\sigma_{f}$
underestimate the linear component of the tuning curves (Fig. \ref{Fig:M1}C).
Nevertheless, this is expected, since our model has no non linearity, which
potentially may increase the linear component of the tuning curves. It is
worth noticing that in the original work, a model with two parameters still
underestimates the distribution of $R^{2}$ values and only the complexity
measure was considered in the fitting procedure. The authors obtained a good
agreement only considering a model with more parameters (namely, different
threshold for each neuron and different widths in the sensory layer).

We also performed simulations with a heterogeneous noise variance across the
population extracted from the data. We assigned to each recorded neuron a
signal-to-noise ratio in the following way. We estimated the variance of the
signal as the variance of the mean responses across different stimuli,
$\hat{R}_{i} = \langle\left(  v_{i}(x) - \langle v_{i}(x) \rangle_{x} \right)
^{2}\rangle_{x}$ . Then, we averaged the trial to trial variability, across
different stimuli, $\hat{\eta}^{2}_{i} = \left\langle \left\langle r^{t}%
_{i}-v_{i}(x)\right\rangle _{t}\right\rangle _{x}$, where $r^{t}$ is the
response at each trial. As in our model we kept the variance of the signal
equal to 1, the noise variance in the $i$-th neuron in simulations was set
equal to
\begin{equation}
\eta_{i}^{2} = \frac{\hat{\eta}_{i}^{2}}{\hat{R}_{i}}. \label{Eq:snr-data}%
\end{equation}
In principle, the noise may be dependent from the mean. To control for this
effect, we also preprocessed the data with a variance stabilizing
transformation (substituting $r(\mathbf{x}) $ with $\sqrt{r(\mathbf{x})}$,
\cite{SRJ1999TheStatistics}). The distribution of the noise variance across
neurons obtained in this way does not vary substantially.

For numerical simulations in Fig. \ref{Fig:6}, the tuning curves are computed
at a finer scale than the data (cubic grid of 21 by 21 by 21 points). As
expected, the tuning curves show a broad range of behavior with respect to the
linear fit, that goes from very linear to very irregular (Fig. \ref{Fig:M1}
D-F). The linear population for the comparison is constructed by sampling the
preferred vectors ,$\mathbf{P}_{i} = (b_{1},c_{2},d_{3})$ , uniformly on the
unit sphere and using Eq. (\ref{Eq:CosTun}) to generate the responses.
Similarly to the irregular ones, these tuning curves are shifted and
normalized to have zero mean and unit variance.

\section{Acknowledgements}
\newpage

%\bibliographystyle{plain}
\bibliography{references}



\end{document}